{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"getting-started.html","title":"Getting Started","text":""},{"location":"Integrations/AlertManager.html","title":"Prometheus/Grafana Alert Manager Integration","text":"<p>The Integration of Grafana / Prometheus AlertManager allows alerts triggered by AlertManager to appear on Komodor's timelines.</p>"},{"location":"Integrations/AlertManager.html#installation","title":"Installation","text":""},{"location":"Integrations/AlertManager.html#the-alert-manager-integration-involves-3-steps","title":"The Alert Manager integration involves 3 steps:","text":"<ol> <li>Enabling the integration in Komodor.</li> <li>Creating webhook on the alert manager / Grafana.</li> <li>Adding labels to the alert.</li> </ol>"},{"location":"Integrations/AlertManager.html#1-enabling-the-integration-in-komodor","title":"1. Enabling the integration in Komodor","text":"<p>To enable the Komodor Prometheus Alert Manager integration go to Komodor integrations page, select Prometheus/Grafana Alert Manager, and install the integration.</p>"},{"location":"Integrations/AlertManager.html#2-option-a-the-following-steps-are-for-manual-configuration-on-alert-manager","title":"2. (Option A) The following steps are for manual configuration on alert manager","text":""},{"location":"Integrations/AlertManager.html#creating-webhook","title":"Creating webhook","text":"<ol> <li>Open your <code>alertmanager.yml</code> configuration file</li> <li>Add a receiver to your receivers list, name the receiver <code>komodor</code> and attach a sink to <code>webhook_configs</code>. In the <code>url</code> field, put the URL that was provided to you during the integration setup. Also set the field <code>send_resolved</code> to <code>true</code>.</li> </ol> <pre><code>receivers:\n- name: komodor\nwebhook_configs:\n- url: \"&lt;URL_FROM_KOMODOR&gt;\"\nsend_resolved: true\n</code></pre> <ol> <li>Next, in <code>alertmanager.yml</code>, configure a route so that your alert is routed to komodor</li> </ol> <pre><code>route:\nreceiver: komodor\n</code></pre> <p>If you already have configured routes you can config multiple as follows:</p> <pre><code>routes:\n- match:\nseverity: critical\nreceiver: pagerduty\n- match:\nreceiver: komodor\n</code></pre> <p>A note about the <code>continue</code> configuration of AlertManager routing rules. If it is set to false, AlertManager sends the alert to the first matching route and stops. <code>continue</code> default value is false.</p> <p>A full YAML configuration example:</p> <pre><code>global:\ngroup_interval: 5m\nrepeat_interval: 12h\nroutes:\n- match:\nreceiver: komodor\nreceivers:\n- name: komodor\nwebhook_configs:\n- url: \"&lt;URL_FROM_KOMODOR&gt;\"\nsend_resolved: true\n</code></pre>"},{"location":"Integrations/AlertManager.html#2-option-b-configure-alerts-from-grafana","title":"2. (Option B) Configure alerts from Grafana","text":"<ol> <li>Go to <code>Alerting</code> -&gt; <code>Contact points</code>.</li> </ol> <ol> <li>Click <code>New contact point</code>.</li> </ol> <ol> <li>Enter in name <code>komodor</code>, in <code>Contact point type</code> select <code>Webhook</code> and in <code>Url</code> insert the URL from the UI.</li> </ol> <ol> <li>Click <code>Alerting</code> -&gt; <code>Notification policies</code>.</li> </ol> <ol> <li>In the notification policies, configure komodor contact endpoint as you wish to configure alerts to Komodor.</li> </ol>"},{"location":"Integrations/AlertManager.html#3-adding-labels-to-the-alert","title":"3. Adding labels to the alert.","text":"<p>To relate the alert to the relevant workload and make the alerts visible on workloads timelines - adding labels to alerts is required. Each alert without a label will be added to the system without mapping to a specific service.</p> <ol> <li>Please note to specify 2 labels on the alert in order to connect them to the Kubernetes workload:</li> </ol> <pre><code>service: &lt;workload-name&gt;\ncluster: &lt;cluster-name&gt;\n</code></pre> <ol> <li>[Optional] defining custom description to the alert on Komodor (specify it in the annotation):</li> </ol> <pre><code>description: &lt;content&gt;\n</code></pre>"},{"location":"Integrations/ArgoCD.html","title":"ArgoCD","text":""},{"location":"Integrations/ArgoCD.html#argocd-integration","title":"ArgoCD integration","text":"<p>This tutorial demonstrates how to utilize ArgoCD\u2019s external links to seamlessly hop from a specific K8s resource on Argo to its parallel on Komodor. This is meant to reduce friction and context-swtiching when troubleshooting incidents.</p> <p>Komodor is a continuous reliability platform for Kubernetes that collects all changes and events across your system, provides a coherent timeline view, and offers actionable insights for remediation.  </p>"},{"location":"Integrations/ArgoCD.html#general","title":"General","text":"<p>ArgoCD can generate clickable links to external pages for a resource based on per resource annotation.</p> <p>Adding a Komodor dynamic link to ArgoCD will generate a direct link from an ArgoCD application to the relevant workload in Komodor, based on the Kubernetes workload resources annotation.</p> <p>Thus providing a way to quickly get the full context of an incident and resolve it end-to-end with minimal effort.</p>"},{"location":"Integrations/ArgoCD.html#why-use-komodor-on-top-of-argocd","title":"Why use Komodor on top of ArgoCD?","text":"<ul> <li>To resolve incidents in complex and distributed environments you need full context which can only be understood by looking at changes and events over time </li> <li>Komodor provides visibility to all resources and not only ArgoCD managed apps</li> <li>Komodor can compliment Argo with more capabilities dedicated specifically for rapid incident response. </li> </ul>"},{"location":"Integrations/ArgoCD.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Installed ArgoCD</li> <li>Installed Komodor </li> </ul>"},{"location":"Integrations/ArgoCD.html#installation","title":"Installation","text":"<ol> <li>Add annotations to the requested Kubernetes workload resources </li> <li>The URL should follow the structure bellow <pre><code>https://app.komodor.com/main/deep-dive/{{account-name}}.{{cluster}}-{{namespace}}.{{service}}\n</code></pre> </li> </ol>"},{"location":"Integrations/ArgoCD.html#example","title":"Example","text":""},{"location":"Integrations/ArgoCD.html#testing","title":"Testing","text":"<ol> <li>Open the ArgoCD application details page and make sure that the external link icon is visible for the respective resource </li> <li>Click on the external link icon to directly hop onto the relevant workload in Komodor.</li> </ol>"},{"location":"Integrations/ArgoCD.html#demo","title":"Demo","text":"<p>https://user-images.githubusercontent.com/109901035/185045498-18569afc-0871-4903-8c7c-dff80fbda1cd.mov</p>"},{"location":"Integrations/AzureActiveDirectory.html","title":"Azure active directory","text":""},{"location":"Integrations/AzureActiveDirectory.html#register-komodor-app-with-the-microsoft-identity-platform","title":"Register Komodor App with the Microsoft identity platform","text":""},{"location":"Integrations/AzureActiveDirectory.html#under-manage-select-app-registrations-new-registration","title":"Under\u00a0Manage, select\u00a0App registrations\u00a0&gt;\u00a0New registration","text":"<ul> <li>Name: Komodor</li> <li>Supported account types:<ul> <li>Accounts in any organizational directory (Any Azure AD directory - Multitenant)</li> </ul> </li> <li>Redirect URI:<ul> <li>Platform: Web</li> <li>URL: https://auth.komodor.com/login/callback</li> </ul> </li> <li>Click on the <code>Register</code> button</li> </ul>"},{"location":"Integrations/AzureActiveDirectory.html#create-a-client-secret","title":"Create a Client secret","text":"<ul> <li>Select\u00a0Certificates &amp; secrets\u00a0&gt;\u00a0Client secrets\u00a0&gt;\u00a0New client secret<ul> <li>Description: Komodor client secret</li> <li>Expires: choose whatever right for you</li> <li>Click on the <code>Add</code> button</li> <li>Once generated,\u00a0copy its value and save it! This secret value is\u00a0never displayed again\u00a0after you leave this page</li> <li>Make sure to\u00a0record the expiration date, you will need to renew the key before that day to avoid a service interruption</li> </ul> </li> </ul>"},{"location":"Integrations/AzureActiveDirectory.html#add-permissions","title":"Add permissions","text":"<ul> <li>Select\u00a0API permissions\u00a0&gt;\u00a0Add a permission &gt; Microsoft APIs &gt; Microsoft Graph</li> <li>choose Delegated permissions</li> <li>Search Directory</li> <li>choose Directory &gt; Directory.Read.All</li> <li>Click the <code>Add Premission</code> button</li> </ul>"},{"location":"Integrations/AzureActiveDirectory.html#add-another-redirect-uris","title":"Add another Redirect URIs","text":"<ul> <li>Select Authentication &gt; WEB &gt; Add URI</li> <li>Add this url https://komodorio.us.auth0.com/login/callback</li> <li>Save</li> </ul>"},{"location":"Integrations/AzureActiveDirectory.html#done-the-komodor-app-is-registered","title":"Done! The Komodor app is registered \u00a0\ud83c\udf3b","text":""},{"location":"Integrations/AzureActiveDirectory.html#please-send-the-next-values-to-your-contact-at-komodor","title":"Please send the next values to your contact at Komodor:","text":"<ul> <li>Microsoft Azure AD Domain<ul> <li>Your Azure AD domain name. You can find this on your Azure AD directory's overview page in the Microsoft Azure portal.</li> <li></li> </ul> </li> <li>Client ID<ul> <li>Unique identifier for your registered Azure AD application. Enter the saved value of the\u00a0Application (client) ID\u00a0for the app you just registered in Azure AD.</li> <li></li> </ul> </li> <li>Client Secret<ul> <li>String used to gain access to your registered Azure AD application. Enter the saved value of the\u00a0Client secret\u00a0for the app you just registered in Azure AD.</li> </ul> </li> </ul>"},{"location":"Integrations/AzureActiveDirectory.html#resources","title":"resources:","text":"<ul> <li>Auth0 tutorial</li> <li>youtube (old Azure version but a really nice video)</li> </ul>"},{"location":"Integrations/Datadog-Monitor-Notification.html","title":"Datadog Monitor Notification","text":"<p>Adding A Komodor dynamic link to DataDog Monitor Notifications will generate a direct link to the relevant service in Komodor. You will see the alert link in your Alerting provider connected to DataDog.</p>"},{"location":"Integrations/Datadog-Monitor-Notification.html#installation","title":"Installation","text":""},{"location":"Integrations/Datadog-Monitor-Notification.html#prerequisites","title":"Prerequisites","text":"<p>To use DataDog variables in monitor notifications, there are two prerequisites imposed by DataDog:</p> <ol> <li>Make sure there are variables defined for: cluster name, namespace, service name.</li> <li>Make sure the tags are used in the monitor, or grouped by them.</li> </ol>"},{"location":"Integrations/Datadog-Monitor-Notification.html#link-setup","title":"Link Setup","text":"<ol> <li>Make sure the prerequisites above are met.</li> <li> <p>Add the dynamic link to the DataDog monitor notification message: * <code>https://app.komodor.com/main/deep-dive/YourAccountName.{{cluster_name}}-{{namespace}}.{{service_name}}</code></p> </li> <li> <p>Please note variable names will vary depending on your local DataDog setup.</p> </li> </ol> <p>Example:</p> <p>For account <code>greatcompany</code> alerting PagerDuty.</p> <p>variables: cluster_name <code>k8s_clustername</code> ,namespace <code>k8s_namespace</code>, service_name <code>k8s_servicename</code> The dynamic link will be:</p> <pre><code>@pagerduty-Datadog \nhttps://app.komodor.com/main/deep-dive/greatcompany.{{k8s_clustername}}-{{k8s_namespace}}.{{k8s_servicename}}\n</code></pre>"},{"location":"Integrations/Datadog-Monitor-Notification.html#confirmation-and-testing","title":"Confirmation and testing","text":"<ol> <li>Dynamic Komodor link will be added to your next DataDog alert.</li> <li>The link will include the relevant information.</li> </ol>"},{"location":"Integrations/Datadog-Monitor-Notification.html#testing","title":"Testing","text":"<ol> <li>For an end-to-end testing, add the dynamic link to a test monitor and use the 'Test Notification' button in DataDog.  </li> <li>Use the generated link in your alert provider and make sure it directs you to the correct service in Komodor.</li> <li>If the link fails, check the dynamic link prerequisites.</li> </ol>"},{"location":"Integrations/Datadog-Monitor-Notification.html#see-also","title":"See also","text":"<p>DataDog documentation on monitor notifications </p>"},{"location":"Integrations/Datadog.html","title":"Datadog Integration","text":"<p>DataDog integration allows DataDog Monitor Alerts to be available in Komodor and to suggest related service based on services connection deteced by DataDog.</p>"},{"location":"Integrations/Datadog.html#prerequisites","title":"Prerequisites","text":"<p>For Komodor service correlation, your services according to Datadog, the following DataDog's service tags should be available on the resources.</p> <ul> <li>environment - should match the environment specified on the Datadog service (<code>DD_ENV</code>)</li> <li>service - should match the service name specified on the Datadog service (<code>DD_SERVICE</code>)</li> </ul> <p>DataDog's tags can be done by environment variables, labels, and annotations. To do the correlation, the tags must be a string value and not a reference value.</p> <p>For more information about DataDog tags for Kubernetes go into DataDog tagging documentation</p>"},{"location":"Integrations/Datadog.html#installation-steps","title":"Installation Steps","text":"<ol> <li>Make sure the above prerequisites are met.</li> <li>Locate the Datadog installation tile on Komodor Integrations page.</li> <li>Press Install Integration.</li> <li>Follow the on screen instructions.</li> </ol>"},{"location":"Integrations/Datadog.html#confirmation","title":"Confirmation","text":"<ol> <li>A Datadog Integration tile will be added to the top section under Installed Integrations.</li> <li>Your services that interact with each other will appear under the Related Services section in the Komodor services page.</li> </ol>"},{"location":"Integrations/LaunchDarkly.html","title":"LaunchDarkly Integration","text":"<p>Integration with LaunchDarkly extends the holistic view of the environment with flag change events on the timeline.</p> <p>For example:</p> <ul> <li>Feature flag was turned on</li> <li>Feature flag in variation changed</li> <li>Feature flag targeting was changed</li> </ul>"},{"location":"Integrations/LaunchDarkly.html#installation","title":"Installation","text":""},{"location":"Integrations/LaunchDarkly.html#the-launchdarkly-integration-involves-two-parts","title":"The LaunchDarkly integration involves two parts:","text":"<ol> <li>Enabling the integration in Komodor.</li> <li>Creating a LaunchDarkly webhook.</li> </ol>"},{"location":"Integrations/LaunchDarkly.html#enabling-the-integration-in-komodor","title":"Enabling the integration in Komodor","text":"<p>To enable the Komodor LaunchDarkly integration go to Komodor integrations page and select LaunchDarkly </p> <p>This will open a window with the LaunchDarkly webhook URL and sign key  *Note: you can use the <code>LaunchDarkly Webhook Integration</code> link to continue with the webhook creation</p>"},{"location":"Integrations/LaunchDarkly.html#creating-the-launchdarkly-webhook","title":"Creating the LaunchDarkly webhook","text":"<p>To create the LaunchDarkly webhook go to LaunchDarkly Webhook Integration Page and use the values from Komodor's integration page</p> <ol> <li>Name: Your integration's name</li> <li>URL:  Use the URL from the integration window in Komodor </li> <li>Check the \"Sign this webhook\" checkbox</li> <li>Secret: Use the Secret value from the integration window in Komodor  </li> <li>Filter Policy:    To send all LaunchDarkly event to Komodor:</li> <li>press the \"+ Add statment\" </li> <li>Choose resources for this policy statement: <code>proj/*:env/*:flag/*</code></li> <li>Allow or deny actions on the resource: <code>Allow</code></li> <li>Choose actions to allow or deny: <code>All actions</code></li> <li>\"Update statement\" </li> <li>Check \"I have read and agree to the Integration Terms and Conditions\"</li> <li>\"Save Settings\" to finish the integration.</li> </ol>"},{"location":"Integrations/Loft.html","title":"Loft Integration","text":"<p>The Loft integration enables you to install a Komodor agent automatically on every vcluster created by Loft. The vcluster appears in Komodor's UI like a regular cluster and allows users to access, detect, investigate and remediate their own vclusters independently. You can see the full potential of the Loft &lt;&gt; Komodor integration in this Live Demo.</p> <p>In the Demo, there is a detailed explanation on how to configure it using the Loft UI. The steps below include the configuration manifests to create the same environment configuration using Loft Custom Resources.</p> <p></p>"},{"location":"Integrations/Loft.html#integration-process","title":"Integration Process","text":"<ol> <li>Create a Komodor App in Loft</li> <li>Create a vcluster template with the Komodor App</li> <li>Deploy your first vcluster with the Komodor App</li> </ol>"},{"location":"Integrations/Loft.html#step1-create-a-komodor-app-in-loft","title":"Step1: Create a Komodor App in Loft","text":"<p>Before applying this YAML, please create a Kubernetes Cluster integration in Komodor and replace the <code>{{API-KEY}}</code> with the API key Komodor generated for you. Create a Komodor App in loft by applying this application configuration.</p> <pre><code>apiVersion: storage.loft.sh/v1\nkind: App\nmetadata:\n  name: komodor\nspec:\n  access:\n  - subresources:\n    - '*'\nusers:\n    - admin\n    verbs:\n    - '*'\n- subresources:\n    - '*'\nusers:\n    - '*'\nverbs:\n    - get\n  config:\n    chart:\n      name: k8s-watcher\n      repoURL: https://helm-charts.komodor.io\n      version: 1.0.18\n    values: |+\n      watcher:\n        clusterName: {{ .Values.clusterName }}\nactions:\n          basic: true\nadvanced: true\n\napiKey: {{API-KEY}}\n\ndisplayName: Komodor\n  icon: https://komodor.com/wp-content/uploads/2022/11/komodor-logo-blue.jpg\n  owner:\n    user: admin\n  parameters:\n  - description: Cluster Name\n    label: Cluster Name\n    required: true\nvariable: clusterName\n</code></pre> <p></p>"},{"location":"Integrations/Loft.html#step-2-create-a-vcluster-template-with-the-komodor-app","title":"Step 2: Create a vcluster template with the Komodor App","text":"<p>Add the Komodor App to the vcluster templates you are using or create a new one using this vcluster template.</p> <pre><code>apiVersion: storage.loft.sh/v1\nkind: VirtualClusterTemplate\nmetadata:\n  name: cluster-with-komodor\nspec:\n  access:\n  - subresources:\n    - '*'\nusers:\n    - admin\n    verbs:\n    - '*'\n- subresources:\n    - '*'\nusers:\n    - '*'\nverbs:\n    - get\n  displayName: cluster-with-komodor-and-apps\n  owner:\n    user: admin\n  template:\n    access: {}\napps:\n    - name: komodor\n      namespace: default\n    helmRelease:\n      chart:\n        name: vcluster\n      values: \"# Additional helm values for the virtual cluster\\n# Loft will automatically\n        add the correct service CIDR \\n# and k3s version to the helm values upon deployment\\nstorage:\\n\n        \\ size: 1Gi\\n\\n# syncer:\\n   # If you don't want to sync ingresses from the\n        virtual cluster to \\n   # the host cluster uncomment the next lines\\n   #\n        extraArgs: [\\\"--disable-sync-resources=ingresses\\\"]\"\nmetadata:\n      creationTimestamp: null\n</code></pre> <p></p>"},{"location":"Integrations/Loft.html#step-3-deploy-your-first-vcluster-with-komodor","title":"Step 3: Deploy your first vcluster with Komodor","text":"<p>Create a new vcluster using the Loft UI or sync an existing one that uses a vcluster template with the Komodor app.</p> <p></p>"},{"location":"Integrations/Loft.html#want-to-simluate-the-exact-scenario-as-explained-in-the-demo-use-these-crs","title":"Want to simluate the exact scenario as explained in the demo? Use these CRs:","text":"<p>In the Demo we showed an example of an application being deployed with the Komodor app. You can use the same configratuion by applying these files:</p> <pre><code>apiVersion: storage.loft.sh/v1\nkind: VirtualClusterTemplate\nmetadata:\n  annotations:\n  name: cluster-with-komodor\nspec:\n  access:\n  - subresources:\n    - '*'\nusers:\n    - admin\n    verbs:\n    - '*'\n- subresources:\n    - '*'\nusers:\n    - '*'\nverbs:\n    - get\n  displayName: cluster-with-komodor-and-apps\n  owner:\n    user: admin\n  template:\n    access: {}\napps:\n    - name: komodor\n      namespace: default\n    - name: my-service\n      namespace: default\n    helmRelease:\n      chart:\n        name: vcluster\n      values: \"# Additional helm values for the virtual cluster\\n# Loft will automatically\n        add the correct service CIDR \\n# and k3s version to the helm values upon deployment\\nstorage:\\n\n        \\ size: 1Gi\\n\\n# syncer:\\n   # If you don't want to sync ingresses from the\n        virtual cluster to \\n   # the host cluster uncomment the next lines\\n   #\n        extraArgs: [\\\"--disable-sync-resources=ingresses\\\"]\"\n---\napiVersion: storage.loft.sh/v1\nkind: App\nmetadata:\n  name: my-service\nspec:\n  access:\n  - subresources:\n    - '*'\nusers:\n    - admin\n    verbs:\n    - '*'\n- subresources:\n    - '*'\nusers:\n    - '*'\nverbs:\n    - get\n  config:\n    chart: {}\nmanifests: |-\n      apiVersion: apps/v1\n      kind: Deployment\n      metadata:\n        name: accounts-api\n        labels:\n          app: komodor-oomkilled\n      spec:\n        replicas: 1\nselector:\n          matchLabels:\n            app: komodor-oomkilled\n        template:\n          metadata:\n            labels:\n              app: komodor-oomkilled\n          spec:\n            containers:\n            - name: komodor-oomkilled\n              image: polinux/stress\n              command: [\"stress\"]\nargs: [\"--vm\", \"10\", \"--vm-bytes\", \"100M\", \"--vm-hang\", \"120\", \"--backoff\", \"10000\", \"--verbose\"]\nresources:\n                requests:\n                  memory: \"120Mi\"\nlimits:\n                  memory: \"120Mi\"\n---\n      apiVersion: v1\n      kind: ConfigMap\n      metadata:\n        name: komodor-python-script\n      data:\n        python-script: |-\n          import time\nimport os\n          def start_service():\n              initialize_connections()\ndef initialize_connections():\n              fetch_configuration()\ndef fetch_configuration():\n              create_connection()\ndef create_connection():\n              conn_auth()\ndef conn_auth():\n              raise Exception(\"Can't perform the requested task - authentication error\")\nstart_service()\n---\n      apiVersion: apps/v1\n      kind: Deployment\n      metadata:\n        annotations:\n          app: main-api\n        labels:\n          app: users-api\n        name: users-api\n      spec:\n        replicas: 1\nselector:\n          matchLabels:\n            app: users-api\n        template:\n          metadata:\n            labels:\n              app: users-api\n          spec:\n            containers:\n            - env:\n              image: python:3.11-alpine\n              name: python\n              command: [\"python\"]\nargs: [\"/usr/share/app/code.py\"]\nvolumeMounts:\n                - name: komodor-python-script\n                  mountPath: /usr/share/app/code.py\n                  subPath: python-script\n            volumes:\n            - name: komodor-python-script\n              configMap:\n                name: komodor-python-script\n  displayName: application-deployment\n  owner:\n    user: admin\n</code></pre>"},{"location":"Integrations/MicrosoftTeams.html","title":"Microsoft Teams Integration","text":"<p>The Teams integration allows you to be notified on issues triggered by Komodor Monitors.</p>"},{"location":"Integrations/MicrosoftTeams.html#configuring-teams-notifications","title":"Configuring Teams Notifications","text":""},{"location":"Integrations/MicrosoftTeams.html#configuration-steps","title":"Configuration Steps","text":"<ol> <li>Open up the Komodor Monitors page. </li> <li>Select the Cluster</li> <li>Select the Monitor type</li> <li>Create/modify Monitor rule, configure it's trigger conditions, the scope on which you'd like to be notified on and specify the Teams channel you want the notification to be sent to.</li> <li>On your first use, you will have to configure a Teams channel, to do so, click on \"Add New Channel\" and follow the guide provided in the UI</li> </ol> <ol> <li>Save the rule</li> </ol>"},{"location":"Integrations/Opsgenie.html","title":"Opsgenie Alert Event Integration","text":"<p>Opsgenie integration allows Opsgenie Alerts to be available in Komodor timelines.</p>"},{"location":"Integrations/Opsgenie.html#installation","title":"Installation","text":""},{"location":"Integrations/Opsgenie.html#the-opsgenie-integration-involves-3-steps","title":"The Opsgenie integration involves 3 steps:","text":"<ol> <li>Enabling the integration in Komodor.</li> <li>Integrate Opsgenie with Webhook.</li> <li>Adding labels to the alert.</li> </ol>"},{"location":"Integrations/Opsgenie.html#1-enabling-the-integration-in-komodor","title":"1. Enabling the integration in Komodor","text":"<p>To enable the Komodor Opsgenie integration go to Komodor integrations page, select Opsgenie and install the integration.</p>"},{"location":"Integrations/Opsgenie.html#2-integrate-opsgenie-with-webhook","title":"2. Integrate Opsgenie with Webhook","text":"<p>Follow the following documentation to create an Opsgenie webhook.  </p>"},{"location":"Integrations/Opsgenie.html#3-adding-labels-to-the-alert","title":"3. Adding labels to the alert.","text":"<p>By default, an Opsgenie alert will be added to the Komodor timeline as a \"Cross-service event\". To associate Opsgenie alerts to specific/multiple workloads, it is required to specify the labels associated with the relevant Kubernetes workloads as extra properties of the Opsgenie alert.</p> <pre><code>&lt;label_name&gt;: &lt;label_value&gt;\n</code></pre>"},{"location":"Integrations/PagerDuty.html","title":"PagerDuty Integration","text":"<p>PagerDuty Integration adds PagerDuty Incident events to your services events.</p> <p>NOTE: We currently only support PD events that originate in Datadog.</p>"},{"location":"Integrations/PagerDuty.html#installation","title":"Installation","text":""},{"location":"Integrations/PagerDuty.html#prerequisites","title":"Prerequisites","text":"<p>In order to connect your Datadog-PD incidents to your services in Komodor, you need to match environment variables found in Datadog to your services in Kubernetes.</p> <p>Please make sure the following environment variables exist in your kubernetes deployment: - <code>DD_ENV</code> should match the environment specified on the Datadog service - <code>DD_SERVICE</code> should match the service name specified on the Datadog service</p>"},{"location":"Integrations/PagerDuty.html#installation-steps","title":"Installation Steps","text":"<ol> <li>Make sure the prerequisites above are met.</li> <li>Locate the PagerDuty installation tile on Komodor Integrations page.</li> <li>Press Install Integration.</li> <li>You will be redirected to Pagerduty and back to Komodor successfully.</li> </ol>"},{"location":"Integrations/PagerDuty.html#confirmation","title":"Confirmation","text":"<ol> <li>A PagerDuty Integration tile will be added to the top section of labeled Installed Integrations.</li> <li>When an issue from Datadog is raised through PD, you will be able to find it in the appropriate Komodor services page.</li> </ol>"},{"location":"Integrations/Sentry.html","title":"Sentry Integration","text":"<p>The Sentry integration allows you to see sentry issues in Komodor. For each service, Komodor automatically maps the relevant Sentry project to Komodor services and allows you to gain a full-service timeline: both relevant changes (deploys, config changes etc\u2019) and issues from Sentry will all be in one place.</p>"},{"location":"Integrations/Sentry.html#installation","title":"Installation","text":""},{"location":"Integrations/Sentry.html#installation-steps","title":"Installation Steps","text":"<ol> <li>Make sure the services you track in Komodor use the SENTRY_DSN environment variable.</li> <li>Locate the Sentry installation tile on the Komodor Integrations page.</li> <li>Click Install Integration.</li> <li>A dialog will open with a webhook URL and a link to Sentry to define an internal integration.</li> <li>Go to your Sentry account and click on settings in the left menu. Click on Developer Settings in the settings menu: </li> <li>Click on + New Internal Integration </li> <li>Name this integration Komodor.</li> <li>Paste the webhook URL in the webhook field: </li> <li>To operate properly Komodor needs these permissions:</li> <li>Project - Read</li> <li>Issue &amp; Event - Read </li> <li>Check the <code>issue</code> webhook checkbox </li> <li>Save changes</li> <li>As soon as you save you will see your \u201cclient secret\u201d. Copy the value: </li> <li>Go back to your Komodor integrations page and paste the value of your client secret to the client secret text box.</li> <li>Click <code>Install</code></li> </ol>"},{"location":"Integrations/Sentry.html#in-your-deploymentyaml","title":"In your deployment.yaml","text":"<p>We use the value of the environment variable <code>SENTRY_DSN</code> to match Sentry Issue events with your services in Komodor.</p> <p>Make sure your kubernetes deployment has the environment variable <code>SENTRY_DSN</code>.</p>"},{"location":"Integrations/Sentry.html#confirmation","title":"Confirmation","text":"<ol> <li>A Sentry Integration tile will be added to the top section under Installed Integrations.</li> <li>Once completed you will be able to see Sentry events in you services view: </li> </ol>"},{"location":"Integrations/Slack.html","title":"Slack Integration","text":""},{"location":"Integrations/Slack.html#overview","title":"Overview","text":"<p>The Slack integration allows you to be notified on issues triggered by Komodor Monitors.</p>"},{"location":"Integrations/Slack.html#requirements","title":"Requirements","text":"<p>Depending on your companies Slack settings a company admin may be required to enable the integration, the same user will need to be a Komodor Admin in order to start the installation from the Komodor integration page.</p> <p>!!! Note The free version of Slack is limited to 10 applications.</p>"},{"location":"Integrations/Slack.html#installation","title":"Installation","text":"<ol> <li>Once logged into the Komodor platform click on the Integrations tab.</li> <li>Locate the Slack integration under the Avaiable Integrations section and click on Install Integration to start, this will forward you to the Slack Workspace login page.</li> </ol> <ol> <li>You might be prompted to login to your Slack workspace, if so login and and click Continue.</li> </ol> <ol> <li>Click on Allow to complete the Slack integration.</li> </ol> <ol> <li>Once completed you will be forwarded back to the Komodor Integration page where you will find the Slack integration listed under the Installed Integrations.</li> </ol>"},{"location":"Integrations/Slack.html#creating-notifications","title":"Creating notifications","text":"<p>To enable notifications use the Monitors tab in the UI </p> <ol> <li>Open up the Komodor Monitors page. </li> <li>Select the Cluster</li> <li>Select the Monitor type</li> <li> <p>Create/modify Monitor rule, configure it's trigger conditions, the scope on which you'd like to be notified on and specify the Slack channel you want the notification to be sent to. </p> </li> <li> <p>Save the rule</p> </li> </ol>"},{"location":"Integrations/Squadcast.html","title":"Squadcast","text":"<p>Send alerts to Squadcast from Komodor</p> <p>Squadcast is a full stack Reliability Management &amp; Incident Response software that's designed to help you promote SRE best practices.</p> <p>Route detailed alerts from Komodor to the right users in Squadcast.</p>"},{"location":"Integrations/Squadcast.html#using-komodor-as-an-alert-source","title":"Using Komodor as an Alert Source","text":"<ol> <li>Navigate to Services -&gt; Service Overview -&gt; select or search for your Service. Expand the accordion -&gt; In the Alert Sources section, click Add.</li> </ol> <ol> <li>Select Komodor. Copy the displayed Webhook URL to configure it within Komodor. Finish by clicking Add Alert Source -&gt; Done.</li> </ol> <p>Important: When an alert source turns Active, it\u2019ll show up under Configured Alert Sources, you can either generate a test alert from the integration or wait for a real-time alert to be generated by the Alert Source. An Alert Source is active if there is a recorded incident via that Alert Source for the Service.</p>"},{"location":"Integrations/Squadcast.html#create-a-squadcast-webhook-alert-in-komodor","title":"Create a Squadcast Webhook Alert in Komodor","text":"<p>(1) Login to Komodor. Navigate to the Monitors page, choose your desired cluster and specific monitor</p> <p>(2) Now, On the Edit Role section, select Webhook as notification definition. Click on Add New Webhook and put in the Name and paste the previously copied Squadcast Webhook URL in the Webhook URL place holder. Then click on Save Monitor</p> <p></p> <p>That's it, you are good to go! Your Squadcast integration is now complete.</p> <p>Whenever Komodor fires an alert, an incident will be created in Squadcast for it. Once Komodor sends a close alert, it will automatically be resolved in Squadcast as well.</p>"},{"location":"Integrations/Webhook.html","title":"Webhook Notification","text":"<p>Komodor supports notifications using a custom webhook.</p>"},{"location":"Integrations/Webhook.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Webhooks via HTTPS only   </li> <li>Desired destination URL  </li> </ul>"},{"location":"Integrations/Webhook.html#define-webhook-notification","title":"Define Webhook Notification","text":"<ol> <li>On the \u201cMonitors\u201d page, choose your desired cluster and specific monitor  </li> <li>On the \u201cEdit Role\u201d section, select \u201cWebhook\u201d as notification definition  If you have already set up a notification channel - choose one from the list, if not, create the wanted channel with the following configuration:<ol> <li>Webhook URL - The destination URL to which notifications will be sent</li> <li>Webhook Name - Choose a meaningful name</li> </ol> </li> <li>Save Monitor  </li> </ol> <p>After completing the monitor configuration, you can use the created channel on any other monitor</p> <p>Webhook notifications will be sent as a POST in JSON format to your webhook endpoint. </p> <p>The webhook feature will allow you to integrate into the following channels:  </p> <ol> <li>Prometheus Alert Manager  </li> <li>ServiceNow notification</li> </ol>"},{"location":"Integrations/Webhook.html#example-of-post-data","title":"Example of POST data","text":"<p>Monitor types: availability, node, PVC, job, cronJob Status: open / close Close time will appear only when the \u201cclose\u201d message is sent\u201d </p> <pre><code>{   \"cluster\": \" production\",\n\"namespace\": \"default\",\n\"serviceName\": \"komodor.production-default.brain-consumer-pg\",\n\"resourceName\": \"brain-consumer-pg\",\n\"status\": \"open\",\n\"startTime\": \"0001-01-01 00:00:00 +0000 UTC\",\n\"closeTime\": \"&lt;no value&gt;\",\n\"monitorType\": \"availability\",\n\"issueURL\": \"https://app.komodor.com/main/deep-dive/komodor.production-default.brain-consumer-pg?timeWindow=-62135596805000-1672945087683&amp;timeframe=custom&amp;eventId=1486f269-e28e-4498-8389-9ca33c1f647a\",\n\"issueDetails\": \"[Terminating ContainersNotReady]\"\n}\n</code></pre>"},{"location":"Integrations/datadog-webhook.html","title":"Datadog Webhook Integration","text":"<p>Komodor-Datadog webhook integration allows Komodor to receive alerts from Datadog Monitors. You will see all alerts in the Komodor Service View.</p>"},{"location":"Integrations/datadog-webhook.html#installation","title":"Installation","text":""},{"location":"Integrations/datadog-webhook.html#prerequisites","title":"Prerequisites","text":"<p>In order for us to connect your services according to Datadog events, the following environment variables should exist on your kubernetes deployments: - <code>DD_ENV</code> should match the environment specified on the Datadog tags - <code>DD_SERVICE</code> should match the service name specified on the Datadog tags</p>"},{"location":"Integrations/datadog-webhook.html#installation-steps","title":"Installation Steps","text":"<ol> <li>Make sure the prerequisites above are met.</li> <li>Locate the Datadog installation tile on Komodor Integrations page.</li> <li>Press Install Integration.</li> <li>Follow the on screen instructions.</li> </ol>"},{"location":"Integrations/datadog-webhook.html#confirmation","title":"Confirmation","text":"<ol> <li>A Datadog Integration tile will be added to the top section under Installed Integrations.</li> </ol>"},{"location":"Integrations/datadog-webhook.html#configuring-the-webhook-in-datadog","title":"Configuring the webhook in Datadog","text":"<ol> <li>Go to Datadog Webhook Integration Setup</li> <li>Create a <code>+ New</code> Webhook</li> <li>Name the webhook <code>komodor</code></li> <li>Enter the webhook server URL in the URL field: https://app.komodor.com/collector/datadog/webhook</li> <li>Copy the following Payload schema into the Payload field:</li> </ol> <pre><code>    {\n\"body\": \"$EVENT_MSG\",\n\"last_updated\": \"$LAST_UPDATED\",\n\"event_type\": \"$EVENT_TYPE\",\n\"title\": \"$EVENT_TITLE\",\n\"date\": \"$DATE\",\n\"org\": {\n\"id\": \"$ORG_ID\",\n\"name\": \"$ORG_NAME\"\n},\n\"id\": \"$ID\",\n\"tags\": \"$TAGS\",\n\"alert\": {\n\"id\": \"$ALERT_ID\",\n\"type\": \"$ALERT_TYPE\",\n\"transition\": \"$ALERT_TRANSITION\",\n\"cycleId\": \"$ALERT_CYCLE_KEY\",\n\"priority\": \"$PRIORITY\",\n\"status\": \"$ALERT_STATUS\",\n\"scope\": \"$ALERT_SCOPE\",\n\"query\": \"$ALERT_QUERY\",\n\"metric\": \"$ALERT_METRIC\",\n\"metric_namespace\": \"$METRIC_NAMESPACE\"\n},\n\"aggregation_key\": \"$AGGREG_KEY\",\n\"link\": \"$LINK\",\n\"snapshot\": \"$SNAPSHOT\",\n\"user\": \"$USER\",\n\"username\": \"$USERNAME\",\n\"email\": \"$EMAIL\"\n}\n</code></pre> <ol> <li>Add a Custom Header <code>X-API-KEY</code> with the Api Key found in the Komodor Integration page from the Datadog integration tile at the bottom of the setup modal in a JSON format.</li> </ol> <pre><code>    {\"X-API-KEY\": \"YOUR_KOMODOR_API_KEY\"}\n</code></pre> <ol> <li>When completed click on <code>Save</code>.</li> <li>For every monitor you wish to receive alerts from in Komodor. Edit the monitor and add <code>@webhook-komodor</code> at the end of the Monitor message.</li> </ol>"},{"location":"Integrations/github.html","title":"Github","text":"<p>ToDo - add github docs</p>"},{"location":"Integrations/gitlab.html","title":"Gitlab","text":"<p>ToDo - create gitlab docs</p>"},{"location":"Integrations/Okta/Okta-Role-Provisioning.html","title":"Okta Role Provisioning","text":""},{"location":"Integrations/Okta/Okta-Role-Provisioning.html#setup","title":"Setup","text":"<p>To facilitate the assignment of Komodor roles via Okta we first need to configure a few things on the organization Okta account.</p>"},{"location":"Integrations/Okta/Okta-Role-Provisioning.html#configure-a-custom-attribute","title":"Configure a custom attribute","text":"<ul> <li> <p>Navigate to the Profile Editor section under Directory  </p> </li> <li> <p>Select the Komodor User profile </p> </li> <li> <p>Select the + Add Attribute button </p> </li> <li> <p>Fill in the form as specified in the image below and save the changes </p> </li> <li> <p>To complete the process, go to the Applications view </p> </li> <li> <p>Select the Komodor / Komodorio app </p> </li> <li> <p>Navigate to the Sign On tab </p> </li> <li> <p>Under the Settings section, click the Edit button, under the SAML 2.0 section open the Attributes (Optional) section </p> </li> <li> <p>Add the following attribute and save the changes </p> </li> <li> <p>Everything is now set to assign Komodor roles through Okta</p> </li> </ul>"},{"location":"Integrations/Okta/Okta-Role-Provisioning.html#adding-roles-to-a-user","title":"Adding Roles to a User","text":"<ul> <li> <p>Navigate to the People section </p> </li> <li> <p>Select the user you'd like to assign roles to </p> </li> <li> <p>In case the Komodor / Komodorio application is not yet assigned to the user: </p> <ul> <li> <p>Click Assign Applications </p> </li> <li> <p>Assign the Komodor / Komodorio application to the user </p> </li> <li> <p>Add the relevant roles you'd like to assign to the user and save the changes </p> </li> </ul> </li> <li> <p>If the Komodor / Komodorio application is already assigned to the user:</p> <ul> <li> <p>Edit the Komodor / Komodorio application assignment  </p> </li> <li> <p>Make the wanted changes and click Save </p> </li> </ul> </li> </ul>"},{"location":"Integrations/Okta/Okta-Role-Provisioning.html#adding-roles-to-a-group","title":"Adding Roles to a Group","text":"<ul> <li> <p>Navigate to the groups section </p> </li> <li> <p>Select the group that you'd like to assign the Komodor app to </p> </li> <li> <p>Navigate to the Applications tab </p> </li> <li> <p>Click the Assign applications button and Assign the Komodor / Komodorio app </p> </li> <li> <p>Specify the Roles you'd wish to assign the group with and Save the assignment </p> </li> </ul>"},{"location":"Integrations/Okta/Okta-Role-Provisioning.html#edit-role-assignent-on-an-existing-group","title":"Edit Role Assignent on an existing group","text":"<ul> <li> <p>Go the the relevant group Applications tab and edit the Komodor / Komodorio application assignment </p> </li> <li> <p>Modify the assigned role ids and save the changes </p> </li> </ul>"},{"location":"Integrations/Okta/Okta-Role-Provisioning.html#adding-members-to-a-group","title":"Adding Members to a Group","text":"<ul> <li> <p>Navigate to the groups section </p> </li> <li> <p>Click the Assign people button </p> </li> <li> <p>Click the + button for each user you'd like to add to the group. Click Done at the end  </p> </li> <li> <p>Navigate to the Applications section </p> </li> <li> <p>Select the Komodor application and navigate to the Assignments tab </p> </li> </ul> <p>Please note: The Type of the assignment defines whether the Individual or Group roles will take over. </p> <ul> <li> <p>To convert the assignment type from Individual to Group, click Convert assignments button  </p> </li> <li> <p>Select the users for whom you'd like to convert the assignment, and click Convert selected (alternatively you can click the Convert all assignments button)  </p> </li> <li> <p>Going back to the previous screen, you can confirm that the assignment type has changed </p> </li> </ul>"},{"location":"Integrations/Okta/Okta.html","title":"Okta Integration","text":"<p>Use Okta's deep, pre-built integrations to securely connect to Komodor.</p> <p>Note: Only Okta administrators can add the Komodor application, if you aren't an Okta administrator, please contact your Okta administrator to have the application added.</p> <p>Follow these steps to integrate Komodor with Okta:</p> <ol> <li> <p>Go to Okta Admin -&gt; Applications -&gt; Browse App Catalog    </p> </li> <li> <p>Search for \"Komodor\".    </p> </li> <li> <p>Then click 'Add'.    </p> </li> <li> <p>Enter any application label you want in 'Application Label'. This is for internal use only and will also be the nickname for the Application.    </p> </li> <li> <p>Go to application -&gt; 'Sign On' tab -&gt; 'Settings' and click 'Edit'.</p> </li> <li> <p>In 'Advanced Sign-on settings' enter variable of 'Account Name' and pass this variable to us, for example: 'Komodorio'.    Please change application username format to Email.    **NOTE once you defined 'companyName' it can't be changed    </p> </li> <li> <p>Click 'View Setup Instructions'.    </p> </li> <li> <p>Send the 'Metadata URL' and Account Name variable to support@komodor.com to complete the Okta setup.    </p> </li> <li> <p>Once Customer Success has completed the setup you can begin to use Okta for SSO.</p> </li> </ol>"},{"location":"Learn/Annotations.html","title":"Komodor kubernetes annotations","text":"<p>Komodor annotations (AKA Komodor as Code), is a method to allow users to configure everything related to Komodor as part of their native k8s yaml. Komodor annotations should be placed in the deployment resource annotations (annotations set on the pod template are ignored)</p>"},{"location":"Learn/Annotations.html#ci-deploy-links","title":"CI-Deploy Links","text":"<p>For each deployment version, you can add a quick link with the job url.</p>"},{"location":"Learn/Annotations.html#how","title":"How","text":"<p><code>app.komodor.com/deploy.job.name:url</code></p> <p>Example:</p> Annotation Values Description Example app.komodor.com/deploy.job.jenkins url Link to Jenkins job that deploys the service https://ci.jenkins-ci.org/computer/job"},{"location":"Learn/Annotations.html#deploy-links","title":"Deploy Links","text":"<p>For each deployment version, you can add a quick link with the relevant filters already in place!</p>"},{"location":"Learn/Annotations.html#how_1","title":"How","text":"<p><code>app.komodor.com/deploy.link.name:url</code></p> <p>Examples:</p> Annotation Values Description Example app.komodor.com/deploy.link.logs url Link for the specific version logs https://app.logz.io/#/dashboard/kibana/discover?_a=env:123.0.1 app.komodor.com/deploy.link.sentry url Link for the specific version Sentry issues https://sentry.io/organizations/rookoutz/issues/?project=1320440&amp;query=sdk.version%3A1.0.1&amp;statsPeriod=14d"},{"location":"Learn/Annotations.html#custom-links","title":"Custom Links","text":"<p>You can create custom links to external and internal applications by crafting your own URL to the application using a skeleton URL and placeholders provided by Komodor. Just copy the URL of the application you want to link to, identify the placeholders in the URL that are used to query the application, and replace them with placeholders for your own use. Please find the below examples as references for common applications.</p>"},{"location":"Learn/Annotations.html#how_2","title":"How","text":"<p><code>app.komodor.com/deploy.link.name:value</code></p> <p>Examples:</p> Annotation Values Description Example app.komodor.com/deploy.link.coralogix url Link for the custom URL, coralogix https://komodortest.coralogix.com/#/query-new/logs?query=(coralogix.metadata.cluster:(%22${cluster}%22))%20AND%20(coralogix.metadata.namespace:(%22${namespace}%22))%20AND%20(coralogix.metadata.service:(%22${service}%22))&amp;time=from:${timestampStart=yyyy-MM-dd'T'HH:mm:ss.SSS},to:${timestampEnd=yyyy-MM-dd'T'HH:mm:ss.SSS} app.komodor.com/deploy.link.logzio url Link for the custom URL, logz.io https://app.logz.io/#/dashboard/kibana/discover?_a=(columns:!(message,kubernetes.namespace_name,kubernetes.container_name,params.clusterName),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:kubernetes.namespace_name,negate:!f,params:(query:default),type:phrase),query:(match_phrase:(kubernetes.namespace_name:${namespace}))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:params.clusterName,negate:!f,params:(query:main),type:phrase),query:(match_phrase:(params.clusterName:${cluster}))),('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'logzioCustomerIndex',key:kubernetes.container_name,negate:!f,params:(query:k8s-events-collector),type:phrase),query:(match_phrase:(kubernetes.container_name:${service})),query:(match_phrase:(kubernetes.container_image:${container[web].image})))),index:'logzioCustomerIndex',interval:auto,query:(language:lucene,query:''),sort:!(!('@timestamp',desc)))&amp;_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:'${timestampStart=yyyy-MM-dd'T'HH:mm:ss.SSS}',to:'${timestampStart=yyyy-MM-dd'T'HH:mm:ss.SSS}'))&amp;discoverTab=logz-logs-tab&amp;switchToAccountId=138828&amp;accountIds=true app.komodor.com/deploy.link.datadog url Link for the custom URL, DataDog https://app.datadoghq.com/apm/traces?query=service%3A${service}%20kube_namespace%3A${namespace}%20env%3A${cluster}&amp;cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&amp;historicalData=true&amp;messageDisplay=inline&amp;sort=desc&amp;streamTraces=true&amp;start=${epochStart}&amp;end=${epochEnd}&amp;paused=true <p>The following values can be used to enrich the URL:</p> Placeholder Value Example ${epochStart} Start Time in Epoch Time ${epochEnd} End Time in Epoch Time ${service} Service Name ${namespace} Namespace Name ${cluster} Cluster Name ${failedPod} * The pod name of a failed pod that triggered this health event* ${container[&lt;name&gt;].image} ** Image name of a container ${container[web].image} ${timestampStart=yyyy-MM-dd'T'HH:mm:ss.SSS} Start Time in custom format*** ${timestampStart=yyyy-MM-dd} ${timestampEnd=yyyy-MM-dd'T'HH:mm:ss.SSS} End Time in custom format*** ${timestampEnd=yyyy-MM-dd} ${yaml[&lt;spec_path&gt;]} Full yaml's path specification ${yaml[metadata.labels.app]} <p>*Not applicable in Service context. **Custom links with a failed pod name will be created on health events only. ***Dates can be crafted using the display guidelines of date-fns https://date-fns.org/v2.25.0/docs/format</p> <p>Example on how to use YAML full path:</p> <pre><code>spec:\nreplicas: 5\nselector:\nmatchLabels:\napp: nginx\ntemplate:\nspec:\ncontainers:\n- name: test\nimage: nginx:1.14.2\nports:\n- containerPort: 80\n- name: test2\nimage: nginx:1.14.2\nports:\n- containerPort: 80\nmetadata:\nlables:\napp.kubernetes.io/name: nginx\napp.kubernetes.io/managed-by: helm </code></pre> YAML Path Value Explanation ${yaml[spec.replicas]} 5 full path usage ${yaml[spec.template.spec.containers[0].name]} test full path usage using path index ${yaml[spec.my_replicas]} undefined path doesn't exist ${yaml[spec.template.spec.containers]} undefined path doesn't resolve to an actual value ${yaml[spec.metadata.template.labels['app.kubernetes.io/name']]} nginx full path usage using dictionary key"},{"location":"Learn/Annotations.html#full-example","title":"Full example","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: annotation-example\nannotations:\napp.komodor.com/service.link.grafana-overall-system-health: \"https://grafana.com/service/annotation-example\"\napp.komodor.com/service.link.datadog: \"https://datadog.com/dashboard/annotation-example\"\napp.komodor.com/service.link.playbook: \"https://docs.google.com/playbook\"\napp.komodor.com/deploy.job.jenkins: \"https://ci.jenkins-ci.org/computer/job\"\napp.komodor.com/deploy.link.logs: \"https://app.logz.io/#/dashboard/kibana/discover?_a=env:1.0.1\"\napp.komodor.com/deploy.link.sentry: \"https://sentry.io/organizations/rookoutz/issues/?project=1320440&amp;query=sdk.version%3A1.0.1&amp;statsPeriod=14d\"\napp.komodor.com/service.link.datadog: \"https://app.datadoghq.com/apm/traces?query=service%3A${service}%20kube_namespace%3A${namespace}%20env%3A${cluster}&amp;cols=core_service%2Ccore_resource_name%2Clog_duration%2Clog_http.method%2Clog_http.status_code&amp;historicalData=true&amp;messageDisplay=inline&amp;sort=desc&amp;streamTraces=true&amp;start=${epochStart}&amp;end=${epochEnd}&amp;paused=true\"\nspec:\nselector:\nmatchLabels:\nrun: example\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\nrun: example\nspec:\ncontainers:\n- name: hello-world\nimage: gcr.io/google-samples/node-hello:1.0.1\nports:\n- containerPort: 8080\nprotocol: TCP\n</code></pre>"},{"location":"Learn/Annotations.html#annotations-best-practices","title":"Annotations Best Practices","text":"<p>At Komodor we believe that k8s annotations are the best method for describing services metadata. This includes all the \u201cextra\u201d fields used to tag and label your services, both for other team members and for external tools. BTW, We collect data from both annotations and labels.</p>"},{"location":"Learn/Annotations.html#where-does-komodor-utilize-annotations","title":"Where does Komodor utilize annotations?","text":"<p>Everywhere! Komodor will use these annotations to create powerful connections between services and enrich service information in the following areas:</p> <ul> <li>Services explorer</li> <li>Related services</li> <li>Events screen</li> <li>Matching alerts to the correct services</li> </ul>"},{"location":"Learn/Annotations.html#official-kubernetes-recommendations","title":"Official Kubernetes recommendations","text":"<pre><code>app.kubernetes.io/component: database\napp.kubernetes.io/part-of: wordpress\napp.kubernetes.io/managed-by: helm\n</code></pre>"},{"location":"Learn/Annotations.html#komodor-recommendations","title":"Komodor recommendations","text":"<pre><code>app.komodor.com/label.team: backend\napp.komodor.com/label.group: infrastructure\napp.komodor.com/label.owners: \"infa-team\"\napp.komodor.com/label.alert-team: \"devs\"\napp.komodor.com/label.Impacted-by: redis\n</code></pre>"},{"location":"Learn/Annotations.html#usage-example","title":"Usage example","text":"<ul> <li>Tagging Team annotations on relevant services and adding relevant metadata on the alert metadata in datadog.</li> <li>Using the Team name in the alert tools (for example PagerDuty) as part of the Komodor labels.</li> </ul>"},{"location":"Learn/Appviews.html","title":"Application Views","text":"<p>Application views allow users to generate a scoped Komodor environment focused on the relevant Kubernetes workloads (Deployments, DaemonSets, StatefulSets, Rollouts, Jobs, CronJobs) selected by the users and their related resources.</p> <p>When creating an Application view, the user will be provided with the Overview section which persist on the following component:</p> <ul> <li>Availability issues histogram - visualizes all the Availability issues associated with your application </li> <li>Resources inventory - provides a list of the resources related to the application  </li> <li>List of open availability issues  </li> <li>List of recent deployments   </li> </ul> <p></p> <p>On top of that, you can easily navigate between the Services, Jobs, Events &amp; Resources sections, those will be scoped to the relevant selected workloads.</p>"},{"location":"Learn/Appviews.html#creating-an-application-view","title":"Creating an Application View","text":"<p>To create an application view click the New app view button</p> <ul> <li>First Application creation </li> <li>Add additonal Application - Open the list box on the top of the navigation toolbar </li> <li>Specify your Application configurations, name, description and selected services </li> <li>Save your application view by selecting Create app view</li> </ul>"},{"location":"Learn/Appviews.html#update-an-application-view","title":"Update an Application View","text":"<p>To update an application view, enter the overview page and click on the settings button on the top right, make the wanted changes and save them.</p>"},{"location":"Learn/Create-API-Token.html","title":"Create Personal Access Token","text":"<p>Review the API documentation here.  </p> <p>To create a personal access token follow the following process:  </p> <ol> <li> <p>Access the settings page </p> </li> <li> <p>Go to the API Keys tab </p> </li> <li> <p>Click \"Generate Key\"  </p> </li> <li> <p>Add a description and click Generate </p> </li> <li> <p>You can now use the generated API key from the table </p> </li> </ol>"},{"location":"Learn/ExternalLinks.html","title":"Komodor External Links","text":"<p>Custom links allow to connect your systems and create an easy navigation from Komodor to your logging, metrics, ticketing &amp; documentation systems with the relevant context.</p>"},{"location":"Learn/ExternalLinks.html#how-it-works","title":"How It Works?","text":"<p>Komodor generate the link based on a link template. After adding the template, Komodor generates the links in each one of the screens.</p> <p>Use the Komodor Smart Links to connect between Komodor to any system that you have!  </p>"},{"location":"Learn/ExternalLinks.html#common-use-cases","title":"Common Use-Cases","text":"<p>Here are a few examples for common use cases:</p> <ul> <li>Add a link on Komodor's availability issues to the logging system dashboard (like Kibana) that is pre-filtered with values like the cluster name, the namespace, the name of the pod, and the relevant timeframe. </li> <li>Add a link on Komodor's availability issues relevant metrics dashboards (Grafana / DataDog / NewRelic) with pre-filtered values like the cluster name, the namespace, the name of the pod, and the relevant timeframe.</li> <li>Add a link from Komodor to the relevant internal documentation.</li> <li>Add a link from Komodor to the relevant support ticket system.</li> </ul>"},{"location":"Learn/ExternalLinks.html#how-to-add","title":"How To Add?","text":"<ol> <li>Go into the one of the services, click on one of the events, go to the links section (in avilability issues, it will be in the deploy section) and click on \"add external link\".  </li> <li>Fill the information in the modal:  </li> </ol> <p>You can define the link to be on a cluster wide scope.</p>"},{"location":"Learn/ExternalLinks.html#how-to-template-your-links","title":"How To Template Your Links?","text":"<ul> <li>Go to the relevant system which you want to add link to it in Komodor.</li> <li>Filter the dashboard with the values that you want to create a deep link which can be templated.</li> <li>Template the link using this documentation.</li> </ul>"},{"location":"Learn/ExternalLinks.html#common-examples","title":"Common Examples","text":""},{"location":"Learn/ExternalLinks.html#datadog-service-logs","title":"DataDog Service Logs","text":"<pre><code>https://app.datadoghq.com/logs?query=service%3Ae${service}&amp;cols=host%2Cservice&amp;index=%2A&amp;messageDisplay=inline&amp;stream_sort=desc&amp;viz=timeseries&amp;from_ts=${epochStart}&amp;to_ts=${epochEnd}&amp;live=true\n</code></pre>"},{"location":"Learn/ExternalLinks.html#datadog-failed-pods-logs","title":"DataDog Failed Pod's Logs","text":"<pre><code>https://app.datadoghq.com/logs?query=service%3A${service}%20pod_name%3A${failedPod}&amp;cols=service&amp;index=%2A&amp;messageDisplay=inline&amp;stream_sort=time%2Cdesc&amp;viz=stream&amp;from_ts=${epochStart}&amp;to_ts=${epochEnd}&amp;live=false\n</code></pre>"},{"location":"Learn/ExternalLinks.html#datadog-pods-dashboard","title":"DataDog Pods Dashboard","text":"<pre><code>https://app.datadoghq.com/dash/integration/30322/kubernetes-pods-overview?tpl_var_cluster=${cluster}&amp;tpl_var_deployment=${service}&amp;tpl_var_namespace=${namespace}&amp;from_ts=${epochStart}&amp;to_ts=${epochEnd}&amp;live=true\n</code></pre>"},{"location":"Learn/ExternalLinks.html#logzio-kibana-failed-podss-logs","title":"Logz.io / Kibana Failed Pods's Logs","text":"<pre><code>https://app.logz.io/#/dashboard/kibana/discover?_a=(columns:!(message),filters:!(),index:'logzioCustomerIndex*',interval:auto,query:(language:lucene,query:'params.kubernetes.pod_name%20%3D%20${failedPod}'),sort:!(!('@timestamp',desc)))&amp;_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:'${timestempStart=yyyy-MM-dd'T'HH:mm:ss.SSS}Z',to:'${timestempEnd=yyyy-MM-dd'T'HH:mm:ss.SSS}Z'))&amp;accountIds=138818&amp;switchToAccountId=138818\n</code></pre>"},{"location":"Learn/ExternalLinks.html#grafana-pod-metrics","title":"Grafana Pod Metrics","text":"<pre><code>http://local.grafana.com/d/6581e46e4e5c7ba40a07646395ef7b23/kubernetes-compute-resources-pod?orgId=1&amp;var-datasource=default&amp;var-cluster=&amp;var-namespace=$(namespace}&amp;var-pod=${failedPod}&amp;from={epochStart}&amp;to=${epochEnd}\n</code></pre>"},{"location":"Learn/ExternalLinks.html#grafana-service-metrics","title":"Grafana Service Metrics","text":"<pre><code>http://104.154.113.136:60001/d/a164a7f0339f99e89cea5cb47e9be617/kubernetes-compute-resources-workload?orgId=1&amp;var-datasource=default&amp;var-cluster=&amp;var-namespace=${namespace}&amp;var-type=deployment&amp;var-workload=${service}&amp;from=${epochStart}&amp;to=${epochEnd}\n</code></pre>"},{"location":"Learn/ExternalLinks.html#loki-failed-pods-logs","title":"Loki Failed Pod's Logs","text":"<pre><code>http://local.grafana.com/d/fRIvzUZMz111/logging-dashboard-via-loki?orgId=1&amp;var-container=${yaml[spec.template.spec.containers[0].name]}&amp;var-pod=${failedPod}&amp;var-stream=All&amp;var-searchable_pattern=&amp;from=${epochStart}&amp;to=${epochEnd}\n</code></pre>"},{"location":"Learn/ExternalLinks.html#loki-deployment-logs","title":"Loki Deployment Logs","text":"<pre><code>http://104.154.113.136:60001/d/fRIvzUZMz111/logging-dashboard-via-loki?orgId=1&amp;refresh=5s&amp;var-container=${yaml[spec.template.spec.containers[0].name]}&amp;var-pod=All&amp;var-stream=All&amp;var-searchable_pattern=&amp;from=${epochStart}&amp;to=${epochEnd}\n</code></pre>"},{"location":"Learn/ExternalLinks.html#argocd-application","title":"ArgoCD Application","text":"<pre><code>https://local.argocd.app/applications/argocd/${yaml[metadata.labels['argocd.argoproj.io/instance']]}?view=tree\n</code></pre>"},{"location":"Learn/Helm.html","title":"HELM","text":""},{"location":"Learn/Helm.html#overview","title":"Overview","text":"<p>As part of Komodor vision of helping Kubernetes users to navigate and troubleshoot their clusters, Komodor provides an extensive UI to view and manage installed Helm charts, and see their revision history and corresponding k8s resources. It also allows performing simple actions like rollback to a previous revision or upgrading to a newer version.</p> <p>Some of the key capabilities are:  </p> <ul> <li>Multiple clusters support  </li> <li>See all installed charts and their revision history   </li> <li>See manifest diff of the past revisions   </li> <li>Browse k8s resources managed by the chart   </li> <li>Easy rollback or upgrade version with a clear and easy manifest diff   </li> </ul>"},{"location":"Learn/Helm.html#pre-requisites","title":"Pre-requisites","text":"<p>Agent version 0.1.158 and above</p>"},{"location":"Learn/Helm.html#agent-permissionsvalues","title":"Agent permissions/values","text":"<p>In order to add those capabilities, the Komodor agent has to have permission to read and manipulate secrets.</p> <p>To add those permissions, enable the following values on the helm chart:  </p> <ul> <li>watcher.resources.secret=true - allows Komodor agent to send secrets to the Komodor SaaS (all secrets are redacted by default)  </li> <li>watcher.enableHelm=true - allows Komodor agent to send Helm-related secrets without redaction  </li> <li>helm.enableActions=true  - adds relevant permissions to the Komodor agent to allow performing various helm-related actions (manipulation of secrets)  </li> </ul>"},{"location":"Learn/Helm.html#upgrade-command","title":"Upgrade command","text":"<p><code>helm repo update; helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.resources.secret=true --set watcher.enableHelm=true --set helm.enableActions=true --reuse-values</code></p>"},{"location":"Learn/Helm.html#permissions","title":"Permissions","text":"<p>You can control who has access to view or modify helm charts within your clusters using Komodor RBAC. The following actions can be specified on the RBAC policy level: <code>manage:helm</code> (allowing the following: update, add and remove repos) <code>read:helm-repo</code> <code>install:helm-chart</code> <code>uninstall:helm-chart</code> <code>revert:helm-chart</code> </p> <p>Please note: account-admin would be able to perform all of those</p>"},{"location":"Learn/Helm.html#releases-charts","title":"Releases (charts)","text":"<p>When entering the HELM section in the Komodor UI, on the releases tab, you can see all your helm charts, you can filter them, and perform various actions on them. </p> <p></p> <p>When viewing a specific release, you can easily get the revision history </p> <p>You can also compare its manifest/values with other revisions. </p>"},{"location":"Learn/Helm.html#helm-actions","title":"Helm Actions","text":"<p>Supported actions for charts: - Change version - will only appear when a repository containing the chart is configured for the relevant cluster.  You\u2019ll be able to select either a newer or older version of that chart. </p> <pre><code>This action performs the following helm command  \n`helm upgrade --install ${name} ${chartName} --create-namespace --namespace ${namespace} --version ${version} --values ${values}`\n</code></pre> <ul> <li>Uninstall - Uninstall a chart. Will perform the following command: <code>helm uninstall RELEASE_NAME [...] [flags]</code> </li> <li>Rollback - Rollback to the chosen version. Will perform the following command:  <code>helm rollback &lt;RELEASE&gt; [REVISION] [flags]</code></li> </ul>"},{"location":"Learn/Helm.html#repositories","title":"Repositories","text":"<p>To enable upgrading HELM charts directly from Komodor you have to add the HELM repositories where your charts reside.</p> <p>In order to view and manage your repositories you need the following permissions: <code>manage:helm</code> (allowing the following: update, add and remove repos) <code>read:helm-repo</code></p> <p>Adding a repository: </p> <p>Adding a repository will add the repository to komodor agent that is running on the chosen clusters.</p> <ul> <li>Navigate to the HELM under the Resources section in Komodor   </li> <li>Switch to the Repositories tab</li> </ul> <p></p> <ul> <li>Click \u201cAdd Repository\u201d  </li> <li>Specify the repository details - Name, URL, and Clusters to associate this repository with  </li> <li>Save the repository</li> </ul> <p></p> <p>Test connection: </p> <p>When adding a repo, Komodor verifies that the Repo is accessible from a public network. </p> <p>In case you are referring to a private repo, ignore the warning</p> <p>Behind the scenes, the Komodor Agent will install those repositories and will use them to initiate the relevant commands. </p> <p>Please note: Currently, the only repo authentication method supported is user:password</p>"},{"location":"Learn/Install-Komodor-Agent.html","title":"Getting started","text":"<p>Welcome to Komodor, the dev-first Kubernetes operations platform \ud83d\udc4b</p> <p>Follow these instructions to quickly install our Agent on the clusters you want to manage, monitor, and track changes on.  To unlock Komodor\u2019s full potential take a deep dive into the feature docs, and join our Slack Kommunity, where you can meet fellow Komodor users, exchange knowledge, and get support from our team.</p>"},{"location":"Learn/Install-Komodor-Agent.html#what-is-komodor","title":"What is Komodor","text":"<p>Komodor is a Kubernetes operations platform for developers, complete with automated playbooks for every K8s resource, and static-prevention monitors that enrich live &amp; historical data with contextual insights to help enforce best practices and stop incidents in their tracks.  By baking K8s expertise directly into the product, Komodor is accelerating development cycles, reducing MTTR, and empowering dev teams to manage their K8s apps efficiently and independently.</p>"},{"location":"Learn/Install-Komodor-Agent.html#agent-install","title":"Agent Install","text":""},{"location":"Learn/Install-Komodor-Agent.html#requirements","title":"Requirements","text":"<ul> <li>Installed kubectl command-line tool.</li> <li>Have a kubeconfig file (default location is ~/.kube/config).</li> <li>Have an active connection to the desired cluster</li> <li>Installed Helm3 or Kustomize</li> </ul>"},{"location":"Learn/Install-Komodor-Agent.html#permissions","title":"Permissions","text":"<p>The Komodor agent uses the native RBAC model of Kubernetes. All the permissions are listed here:</p> <ol> <li>helm</li> <li>kustomize base, kustomize final</li> </ol>"},{"location":"Learn/Install-Komodor-Agent.html#step-1-sign-up-to-komdor","title":"Step 1 - Sign up to Komdor","text":"<p>To create your account, sign up for Komodor with your email address or by using SSO via your Google, GitHub or Microsoft accounts.</p>"},{"location":"Learn/Install-Komodor-Agent.html#step-2-installing-the-agent","title":"Step 2 - Installing the Agent","text":"<ul> <li>The main installation method uses Helm 3.0 to install the Komodor Agent on your cluster</li> <li>If you aren\u2019t using Helm, you can install the Agent with Kustomize, or with our guided installation script using Bash [Linux/Mac] or Powershell [Windows]</li> <li>You can also install the Agent manually using the Helm command template below</li> </ul>"},{"location":"Learn/Install-Komodor-Agent.html#guided-install","title":"Guided install","text":"<p>  1. Pick the relevant script: Powershell (Windows) or Bash (Linux/Mac), run it in your shell/terminal and follow the steps in the installation script.  2. Our guided install script will run the following actions for you:</p> <ul> <li>Make sure you have KubeCTL</li> <li>Get the cluster from your current context (If you want to install on a different context - change it and run the command again)</li> <li>Set the cluster display name in Komodor using the current context (You can choose to use a custom name if you prefer)</li> <li>Verify you have the latest version of Helm</li> <li>Run and install the Agent using Helm</li> </ul>"},{"location":"Learn/Install-Komodor-Agent.html#helm-install","title":"Helm install","text":"<ol> <li>Pick Helm out of the installation options.</li> <li>The Helm command generates a unique API key and defines the cluster name.</li> <li>Copy the Helm command into your terminal, and run the command.</li> </ol>"},{"location":"Learn/Install-Komodor-Agent.html#template-for-manual-helm-install","title":"Template for manual Helm install","text":"<p>You can also manually build and run the following Helm command:</p> <pre><code>helm repo add komodorio https://helm-charts.komodor.io\nhelm repo update\nhelm upgrade --install k8s-watcher komodorio/k8s-watcher \\\n--set apiKey=YOUR_API_KEY_HERE \\\n--set watcher.clusterName=CLUSTER_NAME \\\n--set watcher.enableAgentTaskExecution=true \\\n--set watcher.allowReadingPodLogs=true\n</code></pre>"},{"location":"Learn/Install-Komodor-Agent.html#kustomize-install","title":"Kustomize install","text":"<p>Alternatively you can use the following Kustomize command:</p> <pre><code>export KOMOKW_API_KEY= # API KEY Required\nexport KOMOKW_CLUSTER_NAME= # Cluster name the will be presented in Komodor\nkubectl create ns komodor\nkubectl apply -n komodor -k https://github.com/komodorio/helm-charts/manifests/overlays/full/?ref=master\n</code></pre> <p>The API key can be found in the Integration page.</p>"},{"location":"Learn/Install-Komodor-Agent.html#step-3-integrate-additional-clusters","title":"Step 3 - Integrate additional clusters","text":"<ol> <li> <p>Go to the Integration page by clicking the Integrations tab on the lefthand navigation menu. </p> </li> <li> <p>Click on \u2018Add Cluster\u2019 in the Kubernetes cluster integration prompt. </p> </li> </ol> <p>Follow the installation instructions in step2</p>"},{"location":"Learn/Install-Komodor-Agent.html#step-4-start-exploring-the-platform","title":"Step 4 - Start exploring the platform","text":"<p>After installing the Komodor Agent you will be able to view all the K8s resources in your clusters on the Komodor platform web UI. </p> <p></p> <p>To unlock Komodor\u2019s full potential take a deep dive into the feature docs. Take a glance below at some of the key capabilities Komodor has to offer. </p> <p>\ud83d\udc41\ufe0f Observe: Cross-cluster Visibility Uncover your resources with a robust K8s dashboard Easily explore and navigate through your Kubernetes resources across clusters from a single pane of glass View metrics, logs, K8s events and inspect resources in real-time</p> <p>Learn how to set up your first monitors for each K8s resource</p> <p>\u2699\ufe0f Manage: Simplified Cluster Management Easily run day-to-day operations like restarting a service, rollbacks, comparing resources, setting requests/limits, etc. Control more complex configurations by editing resources, manifests and config files Validate your K8s configurations with real-time feedback for best practices</p> <p>Learn how to interact with your K8s cluster using Komodor</p> <p>\ud83d\udee0\ufe0f Troubleshoot: Automated and Guided View the entire history of changes and events to quickly correlate issues Instantly know if an issue is infra or app-related Run automatic playbooks for common K8s incidents Get simple remediation instructions and take action with just one click</p> <p>Learn how to use Komodor to troubleshoot issues in your K8s application</p>"},{"location":"Learn/Install-Komodor-Agent.html#advanced-configuration","title":"Advanced Configuration","text":"<p>To learn more about advance configuration for the Komodor agent - Read here </p>"},{"location":"Learn/Interaction-With-The-Cluster.html","title":"Interaction with the Cluster","text":"<p>Interaction with the cluster allows you to speed up the troubleshooting process. This is done by asking Komodor's agent to perform actions in the cluster.</p>"},{"location":"Learn/Interaction-With-The-Cluster.html#prerequisites","title":"Prerequisites","text":"<p>Install Komodor's watcher (version <code>&gt;=0.1.44</code>) <code>--set watcher.enableAgentTaskExecution=true</code> to start the agent with the feature turned on (required for Describe Action)</p>"},{"location":"Learn/Interaction-With-The-Cluster.html#extra-permissions-required","title":"Extra Permissions Required","text":"<p>In order to get logs from the cluster please use <code>--set watcher.allowReadingPodLogs=true</code> to update the RBAC manifests with the required permissions (required for Pod Log Action)</p> <p>You can turn any of these flags off at any time to disable the features</p>"},{"location":"Learn/Interaction-With-The-Cluster.html#upgrade","title":"Upgrade","text":"<pre><code>helm repo update\nhelm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.enableAgentTaskExecution=true --set watcher.allowReadingPodLogs=true --reuse-values\n</code></pre>"},{"location":"Learn/Interaction-With-The-Cluster.html#live-pods","title":"Live Pods","text":"<p>In the service, click on the <code>Pod Status and Logs</code> button.</p> <p></p> <p>The table shows all the pods that belong to the service based on the pod owner controller. </p>"},{"location":"Learn/Interaction-With-The-Cluster.html#actions","title":"Actions","text":""},{"location":"Learn/Interaction-With-The-Cluster.html#pod-logs","title":"Pod Logs","text":"<p>Request logs from one of the pods will stream back the last 100 logs from the pod. </p> <p>When a pod was previously restarted by Kubernetes you can see the logs just before the pod was restarted.</p>"},{"location":"Learn/Interaction-With-The-Cluster.html#pod-description","title":"Pod Description","text":"<p>Request returns the same output as <code>kubectl describe pod [NAME]</code> </p>"},{"location":"Learn/Komodor-Agent.html","title":"The Komodor Agent","text":""},{"location":"Learn/Komodor-Agent.html#permissions","title":"Permissions","text":"<p>The Komodor agent uses the native RBAC model of Kubernetes. All the permissions are listed here:</p> <ol> <li>helm</li> <li>kustomize base, kustomize final</li> </ol>"},{"location":"Learn/Komodor-Agent.html#arm-support","title":"ARM Support","text":"<p>Arm64 image is supported via docker manifest. </p>"},{"location":"Learn/Komodor-Agent.html#advanced-configuration","title":"Advanced Configuration","text":"<p>You can configure the agent's functionality using the following configuration file: <code>komodor-k8s-watcher.yaml</code> (assuming the RBAC permissions are satisfied). A more detailed list of the configurable parameters can be found here</p>"},{"location":"Learn/Komodor-Agent.html#data-redaction","title":"Data Redaction","text":"<p>Learn how to set up data redaction in Komodor</p>"},{"location":"Learn/Komodor-Agent.html#resources","title":"Resources","text":"<p>By default, the Komodor agent watches the majority of the resources in your cluster. You can enable/disable watching a resource using the following command:</p> <ol> <li>Helm: <code>--set watcher.resources.RESOURCE=true/off</code></li> <li>Kustomize: update the configuration file and the RBAC rule to have <code>get</code>, <code>list</code> and <code>watch</code> permissions</li> </ol>"},{"location":"Learn/Komodor-Agent.html#namespaces","title":"Namespaces","text":"<p>The Komodor agent watches all the namespaces (by default <code>watchNamespace=all</code>)</p> <p>To watch a single namespace use the following command:</p> <ol> <li>Helm: <code>--set watcher.watchNamespace=NAMESPACE</code></li> <li>Kustomize: patch the configuration file <code>watchNamespace=NAMESPACE</code></li> </ol>"},{"location":"Learn/Komodor-Agent.html#denylist","title":"Denylist","text":"<p>Using <code>namespacesDenylist</code> you can opt list of namespaces</p>"},{"location":"Learn/Komodor-Agent.html#agent-tasks","title":"Agent Tasks","text":"<p>Agent tasks are used to interact with the cluster on demand, read more about interaction with the cluster here</p> <p>To enable agent tasks (default is <code>off</code>):</p> <ol> <li>Helm: <code>--set watcher.enableAgentTaskExecution=true &amp;&amp; --set watcher.allowReadingPodLogs=true</code></li> <li>Kustomize: The <code>full</code> overlay already has this turned on. If you are building it manually from <code>base</code>, patch the configuration file <code>enableAgentTaskExecution=true</code> and make sure to have RBAC permissions to <code>get</code> and <code>list</code> for <code>pods</code> and <code>pods/log</code></li> </ol>"},{"location":"Learn/Komodor-Agent.html#environment-variables","title":"Environment Variables","text":"<p>Alternativly, you can pass the configuration as environment variables using the <code>KOMOKW_</code> prefix and by replacing all the . to _, for the root items the camelcase transforms into underscores as well.</p> <p>For example:</p> <pre><code># apiKey\nKOMOKW_API_KEY=1a2b3c4d5e6f7g7h\n# watcher.resources.replicaSet\nKOMOKW_RESOURCES_REPLICASET=false\n\n# watcher.watchNamespace\nKOMOKW_WATCH_NAMESPACE=my-namespace\n# watcher.collectHistory\nKOMOKW_COLLECT_HISTORY=true\n</code></pre>"},{"location":"Learn/Komodor-Agent.html#updating-the-agent","title":"Updating the agent","text":""},{"location":"Learn/Komodor-Agent.html#kustomize","title":"Kustomize","text":"<pre><code>kubectl apply -n komodor -k https://github.com/komodorio/helm-charts/manifests/overlays/full/?ref=master\n</code></pre>"},{"location":"Learn/Komodor-Agent.html#helm","title":"Helm","text":"<pre><code>helm repo update\nhelm upgrade --install k8s-watcher komodorio/k8s-watcher --reuse-values\n</code></pre>"},{"location":"Learn/Komodor-Agent.html#uninstalling","title":"Uninstalling","text":""},{"location":"Learn/Komodor-Agent.html#kustomize_1","title":"Kustomize","text":"<pre><code>kubectl delete ns komodor\n</code></pre>"},{"location":"Learn/Komodor-Agent.html#helm_1","title":"Helm","text":"<pre><code>helm uninstall k8s-watcher\n</code></pre>"},{"location":"Learn/ManageUsers.html","title":"How to Manage Users","text":"<p>This article will detail how to Invite, Modify and Delete users in the Komodor platform.</p>"},{"location":"Learn/ManageUsers.html#how-to-inviteadd-a-new-user","title":"How to Invite/Add a new user","text":"<ol> <li>To invite another user click on the manage team icon in the top right corner, this will take you to the \"Manage Team\" page.</li> </ol> <p>Note: You must have the Admin role in order to invite another Admin to the platform.</p> <ol> <li>Click on \"Add Member\".</li> </ol> <p></p> <ol> <li>Provide the users Full Name, Email Address and select a role for the user and then click \"Send Invite\" to invite the user to the platform.</li> </ol> <p></p> <p>Note: More on user roles can be found here.</p> <ol> <li>The user will receive an invitation to the platform, click \"Close\" to finish.</li> </ol> <p></p>"},{"location":"Learn/ManageUsers.html#how-to-modify-an-existing-user","title":"How to modify an existing user","text":"<ol> <li>Click on the manage user icon in the top right corner, this will take you to the \"Manage Team\" page.</li> </ol> <ol> <li>You will see a list of users for the account, select \"Edit\" to the far right of the user you wish to modify.</li> </ol> <ol> <li>In the \"Edit Member\" dialogue, modify the users Full Name or Role and click on \"Save Details\" to save the changes.</li> </ol> <p>Note: In order to change a users email address you will need to create a new user by inviting them to the platform using their new email address. </p>"},{"location":"Learn/ManageUsers.html#how-to-delete-a-user","title":"How to delete a user","text":"<ol> <li>Click on the manage user icon in the top right corner, this will take you to the \"Manage Team\" page.</li> </ol> <ol> <li>You will see a list of users for the account, select \"Edit\" beside the user you wish to delete.</li> </ol> <ol> <li>On the \"Edit Member\" dialogue, click on the red garbage bin in the top right corner to delete the user.</li> </ol> <ol> <li>Click on \"Yes, Remove\" to delete the user.</li> </ol>"},{"location":"Learn/Metrics.html","title":"Metrics","text":"<p>Komodor enables you to overview metrics like cpu and memory on your cluster using the prometheus metrics server.</p> <p>NOTE: We also support prometheus that is installed by GrafanaLabs managed service</p>"},{"location":"Learn/Metrics.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Agent version from 0.1.108</li> <li>Installed prometheus on your cluster</li> </ul> <p>Coming soon: prometheus installation integration!</p>"},{"location":"Learn/Metrics.html#how-does-it-work","title":"How does it work?","text":"<p>Komodor agent identifies Prometheus in the cluster and saves the configuration details. The agent sends an HTTP request to the Prometheus metrics server and gets matric results like CPU and memory. The received data is processed and displayed in the Pods and Nodes screens.</p>"},{"location":"Learn/Metrics.html#pods","title":"Pods:","text":"<p>Data is displayed in 2 columns:</p> <ul> <li>%CPU/R - percentage of cpu usage per request</li> <li>%MEM/R - percentage of memory usage per request</li> </ul> <p></p> <p>More columns can be added: %CPU/L, %MEM/L, CPU, Memory</p> <p></p>"},{"location":"Learn/Metrics.html#nodes","title":"Nodes:","text":"<p>Data is displayed in 3 columns:</p> <ul> <li>%CPU - utilization of CPU allocation in percentage</li> <li>%Memory - utilization of memory allocation in percentage</li> <li>%Disk - utilization of disk capacity in percentage</li> </ul> <p></p> <p>More usage columns can be added: CPU, Memory, Disk</p>"},{"location":"Learn/Metrics.html#add-metrics-integration","title":"Add metrics integration","text":"<p>In case you have prometheus in your cluster and the agent doesn\u2019t identify it you can add metrics integration.</p>"},{"location":"Learn/Metrics.html#steps","title":"Steps:","text":"<ol> <li>Go to integration screen and click on Prometheus metrics server</li> </ol> <ol> <li> <p>Enter the fqdn as follows: <code>&lt;namespace&gt;/&lt;service&gt;:&lt;port&gt;</code></p> </li> <li> <p>Namespace - prometheus service namespace</p> </li> <li>Service - prometheus service name</li> <li>Port - The port that prometheus service is listening to</li> </ol> <ol> <li>Choose how you installed prometheus: helm or other operator</li> <li>Click install</li> </ol>"},{"location":"Learn/Monitors.html","title":"Monitors","text":"<p>Komodor Monitors are built to detect different scenarios, investigate certain aspects around them and provide additional context to simplify the troubleshooting process and reduce the MTTR.</p>"},{"location":"Learn/Monitors.html#supported-configurations-per-monitor","title":"Supported configurations per Monitor:","text":"<p>Komodor monitors are being configured on a cluster level, each monitor supports the following configurations:</p> <ul> <li>Trigger conditions - specify when this monitor should be triggered, conditions vary per monitor.</li> <li>Scope - which resources should be monitored, the scope can be configured for the entire cluster, specific namespaces, annotations or labels, the relationship between the selected resources is currently OR relationship.</li> <li>Sink/Notification - where do you want to receive notifications (Slack/Teams/OpsGenie/PagerDuty).</li> </ul>"},{"location":"Learn/Monitors.html#prerequisites","title":"Prerequisites:","text":"<p>Required agent version - 1.0.78 (recommended - latest version)</p>"},{"location":"Learn/Monitors.html#availability-monitor","title":"Availability Monitor","text":"<p>Monitor your workload\u2019s health (available replicas &lt; desired replicas), creates an Availability issue on the Events and Service timelines that provides relevant information to resolve the issue. The Availability monitor will not be triggered during an active rollout.</p> <p>Please note Modifying the scope of an Availability monitor might affect (remove) events from the timeline.</p> <ul> <li> <p>Monitor is triggered by -   Service (Deployment/DaemonSet/Rollout/StatefulSet) number of available replicas &lt; desired replicas by the specified conditions for the defined duration</p> </li> <li> <p>The following checks are performed -</p> </li> <li>Pods health     Foreach Pod we'll provide the following: - Phase, Reason, Pod events - Containers list with their state, reason &amp; logs</li> <li>Service latest deployments</li> <li>Service describe</li> </ul> <p>Please note Data provided in the Availability issue checks is a snapshot in time for when the issue occurred.</p> <p>Please note It is possible to costume your notifications to alert for specific error categories.</p> <p>Each category is including the following reasons :</p> Category Reasons NonZeroExitCode NonZeroExitCode Unhealthy Unhealthy OOMKilled OOMKilled, NonZeroExitCode - Exit code: 137 Creating/Initializing ContainerCreating, PodInitializing, PodNotReady, ContainersNotReady, ReadinessGatesNotReady BackOff BackOff, CrashLoopBackOff, ImagePullBackOff Infrastructure NodeNotReady, NetworkNotReady, Evicted,NodeShutdown, Terminated, Preempted Pending FailedScheduling, NotTriggerScaleUp, PodPending, NodeAffinity Image ErrImagePull, InvalidImageName Volume/Secret/ConfigMap FailedMount, FailedAttachVolume, CreateContainerConfigError Container Creation CreateContainerError, RunContainerError, ContainerCannotRun, ContainerStatusUnknown Pod Termination FailedPreStopHook, FailedKillPod Completed Completed Other Any reason that was not mapped in other categories"},{"location":"Learn/Monitors.html#deploy-monitor","title":"Deploy Monitor","text":"<p>A Deploy monitor will be trigerred whenever a resource is being deployed/rolled-out. Using the Deploy Monitor configuration you can define on what resources (scope) and in what occasion (failed deploy/successful deploy/both) when you would like to get a notification in one of your notification channel (Slack/Teams) </p>"},{"location":"Learn/Monitors.html#node-monitor","title":"Node Monitor","text":"<p>Monitors Nodes with faulty Conditions.</p> <ul> <li>Monitor is triggered by -   Node Conditions change to a faulty Condition, the faulty condition/s last through the configured Duration</li> <li>We perform the following checks as part of our investigation</li> <li>Is the node ready?</li> <li>Is the node overcommitted?</li> <li>Is the node under pressure?</li> <li>Are system Pods healthy?</li> <li>Is the network available?</li> <li>Are Pods being evicted?     -Are user pods healthy?</li> <li>Is the node scheduable?</li> <li>Node overall resource consumption including top 5 pod consumers (requires metric-server installed)</li> <li>Notes</li> <li>The Node detector currently does not deal with nodes in an Unknown state (this means Spot interruptions or scale-down events will not be handled by the WF, could affect other scenarios as well)</li> <li>Will only run on Nodes that are created for more than 3 minutes (there is a 3-minute delay from Node create time prior to running the WF)</li> </ul>"},{"location":"Learn/Monitors.html#pvc-monitor","title":"PVC Monitor","text":"<p>Monitors PVCs in a pending state.</p> <ul> <li>Triggered by -   PVC in a pending state for the defined duration</li> <li>We perform the following checks as part of our investigation</li> <li>PVC creation, utilization, and readiness issues</li> <li>Volume provisioner related issues</li> <li>PVC spec change</li> <li>Identify the impact on your services</li> </ul>"},{"location":"Learn/Monitors.html#job-monitor","title":"Job Monitor","text":"<p>The Job Monitor will be triggered when a job fails execution. It allows you to get notified for Job failures on the defined scope.</p>"},{"location":"Learn/Monitors.html#cronjob-monitor","title":"CronJob Monitor","text":"<p>The CronJob Monitor will be triggered when a job (managed by CronJob) fails execution. It allows you to get notified for the first (first failure ater a success) or any CronJob failures on the defined scope.</p>"},{"location":"Learn/RBAC.html","title":"Role-Based Access Control","text":""},{"location":"Learn/RBAC.html#intro","title":"Intro","text":"<p>Komodor allows assigning users with Roles to control their access and permissions (such as what data they can read or which resources they can modify).</p>"},{"location":"Learn/RBAC.html#komodor-roles","title":"Komodor Roles","text":"<p>Roles are built from one or more policies.</p>"},{"location":"Learn/RBAC.html#built-in-roles","title":"Built-in Roles","text":"<ul> <li>account-admin - has full permissions on the account</li> <li>viewer - has access to view all resources on the account</li> <li>developer - has access to view all resources and perform the following basic actions:</li> </ul> <pre><code>    \"delete:pod\",\n    \"scale:deployment\",\n    \"scale:statefulset\",\n    \"restart:deployment\",\n    \"restart:statefulset\",\n    \"rerun:job\"\n</code></pre> <p>Learn more about actions </p> <p>Please note - The built-in account-admin role and policy cannot be modified, there has to be at-least one account-admin on the account, the last account-admin cannot be removed or provided with a different role.</p>"},{"location":"Learn/RBAC.html#komodor-policies","title":"Komodor Policies","text":"<p>Policies define a set of actions &amp; resources they can performed at.</p> <p>A policy is built from a list of Statements, formatted as follows:</p> <pre><code>[   \n    {\n        \"actions\": [],\n        \"resources\": []\n    },\n    {\n        \"actions\": [],\n        \"resources\": []        \n    }\n]\n</code></pre>"},{"location":"Learn/RBAC.html#actions","title":"Actions","text":"<p>A list of allowed actions, formatted as follows: <code>action:supported-resource-type</code> </p> <p>List of the supported combinations:</p> Action Supported Resource Types view * (all) edit * (all), deployment, statefulset, daemonset, replicaset, jobs, cronjob, configmap, secret, service, ingress delete * (all), deployment, statefulset, daemonset, replicaset, jobs, cronjob, pvc, pv, storageclasse, secret, service, ingress scale deployment, statefulset restart deployment, statefulset, daemonset manage users, monitors, integrations run cronjob rerun job <p>Please note:  </p> <ul> <li><code>view:all</code> permission is required in any policy to allow viewing anything in Komodor, you can limit the allowed access using the Resources clause  </li> <li><code>manage</code> permissions cannot be scoped, once provided the user will have access to manage all resources of the provided category  </li> <li>Only <code>account-admin</code>s or users with <code>manage:users</code> permission can see the Roles &amp; Policies pages under in the settings section    </li> </ul>"},{"location":"Learn/RBAC.html#resources","title":"Resources","text":"<p>A list of resources, formatted as follows:</p> <pre><code>{\n    \"cluster\": \"*\",\n    \"namespaces\": []\n}\n</code></pre> <p>The cluster clause supports specifying a specific cluster or \"*\" (any). The namespaces clause is optional and allows specifying a list of one or more namespaces. </p>"},{"location":"Learn/RBAC.html#policy-examples","title":"Policy Examples","text":"<p>1 - The following policy allows performing the following actions on resources running in the kube-system namespaces on all clusters and on namespaces brain and k8s-watcher on the cluster named main     - Deletion of Pods     - Scaling all supported resource types      - Restarting all supported resource types   </p> <pre><code>[\n    {\n        \"actions\": [\n            \"view:all\"\n            \"delete:pod\",\n            \"scale:deployment\",\n            \"restart:deployment\",\n        ],\n        \"resources\": [\n            {\n                \"cluster\": \"main\",\n                \"namespaces\": [\n                \"brain\",\n                \"k8s-watcher\"\n                ]\n            },\n            {\n                \"cluster\": \"*\",\n                \"namespaces\": [\n                \"kube-system\"\n                ]\n            }\n        ]\n    }\n]\n</code></pre> <p>2 - The following policy allows viewing all resources and managing all Komodor configurations for all clusters  </p> <pre><code>[\n    {\n        \"actions\": [\n            \"view:all\"\n            \"manage:monitors\"\n        ],\n        \"resources\": [\n            {\n                \"cluster\": \"*\",\n            }\n        ]\n    }\n]\n</code></pre>"},{"location":"Learn/RBAC.html#policy-creation","title":"Policy Creation","text":"<p>You can easily create new policies using the Komodor platform  </p> <ol> <li>Access the settings page </li> <li>Go to the Policies page </li> <li>Add policy  You will now enter a policy creation wizard, you can easily manage your policies with it  </li> <li>Create a role associated with this policy </li> <li>Associate the role to an existing/new user/s   </li> </ol>"},{"location":"Learn/Sensitive-Information-Redaction.html","title":"Sensitive data redaction in Komodor\u2019s k8s-watcher","text":""},{"location":"Learn/Sensitive-Information-Redaction.html#what-is-it","title":"What is it","text":"<p>It\u2019s likely that there are values you don\u2019t want to send to Komodor as plain text. Kubernetes Secrets, for instance, ConfigMap sensitive values, container environment variables or pod logs. When configured - we will redact the specific value. That way Komodor won't see any sensitive data while you will still see configuration diff.</p>"},{"location":"Learn/Sensitive-Information-Redaction.html#how-to-integrate","title":"How to integrate","text":"<p>Inside <code>komodor-k8s-watcher.yaml</code> you should add a list of string or regular expressions under <code>redact</code> and <code>redactLogs</code> key as such:</p> <p>komodor-k8s-watcher</p> <pre><code>watchNamespace: all\nnamespacesBlacklist:\n- kube-system\nredact:\n- \"PG_.*\"\n- \".*PASSWORD.*\"\nredactLogs:\n- \"password=(.+?)\\b\"\n- \"(?U)\\\"sessionId\\\": (\\\".+\\\"{1})\"\nnameBlacklist: [\"leader\", \"election\"]\ncollectHistory: false\n</code></pre>"},{"location":"Learn/Sensitive-Information-Redaction.html#how-to-integrate-using-helm-upgrade-command","title":"How to integrate using helm upgrade command","text":"<pre><code>helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.redact=\"{.*PASSWORD.*,.*password.*,.*KEY.*,.*key.*,.*SECRET.*,.*secret.*}\" --set watcher.redactLogs=\"{password=(.+?)\\b,(?U)\\\"sessionId\\\": (\\\".+\\\"{1})}\" --set apiKey=&lt;API-KEY&gt; --set watcher.clusterName=&lt;cluster-name&gt; --set watcher.enableAgentTaskExecution=true --set watcher.allowReadingPodLogs=true </code></pre>"},{"location":"Learn/Sensitive-Information-Redaction.html#how-to-integrate-using-environment-variables","title":"How to integrate using environment variables","text":"<p>Separate multiple values with a whitespace in the environment variable value. To include a whitespace in the patterns to redact, make sure to use <code>\\s</code> as it the patterns are regexp.</p> <pre><code>export KOMOKW_REDACT=\".*password.* PG_.*\"\nexport KOMOKW_REDACT_LOGS=\"password=(.+?)\\b (?U)\\\"sessionId\\\": (\\\".+\\\"{1})\"\n</code></pre>"},{"location":"Learn/Sensitive-Information-Redaction.html#secret-resource","title":"Secret Resource","text":"<p>By default, Komodor\u2019s agent is hashing all secrets values.</p>"},{"location":"Learn/Sensitive-Information-Redaction.html#configmap-resource","title":"ConfigMap resource","text":"<p>You can preconfigure a list of keys for Kubernetes watcher to also redact specific values from ConfigMap.</p> <p>komodor-k8s-watcher.yaml:</p> <pre><code>redact:\n- \"SENTRY_API_KEY\"\n- \"PG_.*\"\n</code></pre> <p>configmap.yaml:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nName: sensitive-config-map\ndata:\nSENTRY_API_KEY: super_secret\nPG_SECRET: super_secret\nPG_USERNAME: super_secret\n</code></pre> <p>All the above \u201csuper_secret\u201d will be sent has hashed value.</p>"},{"location":"Learn/Sensitive-Information-Redaction.html#deployment-resource","title":"Deployment resource","text":"<p>Komodor\u2019s agent will hash <code>template.spec.template.[containeres|initContainers].env</code> list of variables inside Deployment objects for pre-configured list of keys or list of regular expressions.</p> <p>komodor-k8s-watcher.yaml:</p> <pre><code>redact:\n- \"SENTRY_API_KEY\"\n- \"PG_.*\"\n</code></pre> <p>deployment.yaml:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: sensitive-deployment\nspec:\nselector:\nmatchLabels:\nrun: example\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\nrun: example\nspec:\ncontainers:\n- name: hello-world\nimage: gcr.io/google-samples/node-hello:1.0\nenv:\n- name: PG_USERNAME\nvalue: super_secret\n- name: SECRET\nvalue: this_will_show_up\n</code></pre> <p>In the above deployment example we will not send the secret values for PG_USERNAME.</p> <p>SECRET will show up as is due to the fact it won\u2019t match any string or regex in our configuration.</p>"},{"location":"Learn/Sensitive-Information-Redaction.html#pod-logs","title":"Pod Logs","text":"<p>Note: Pod Logs redaction is available starting from Komodor Agent version 0.1.126</p> <p>Komodor's agent will redact any logs matching one of the patterns set in the <code>redactLogs</code> configuration.</p> <p>komodor-k8s-watcher.yaml:</p> <pre><code>redactLogs:\n- \"password=(.+?)\\b\"\n- \"(?U)\\\"sessionId\\\": (\\\".+\\\"{1})\"\n</code></pre> <p>Environment variables:</p> <pre><code>export KOMOKW_REDACT_LOGS=\"password=(.+?)\\b (?U)\\\"sessionId\\\": (\\\".+\\\"{1})\"\n</code></pre> <p>Example logs:</p> <pre><code>INPUT: example my password=supersecret and something else\nOUTPUT: example my &lt;REDACTED&gt; and something else\n\nINPUT: { \"level\": \"INFO\", \"message\": \"User has added Item 12453 to Basket\", \"sessionId\": \"SESS456\", \"timestamp\": 1634477804 }\nOUTPUT: { \"level\": \"INFO\", \"message\": \"User has added Item 12453 to Basket\", &lt;REDACTED&gt;, \"timestamp\": 1634477804 }\n</code></pre>"},{"location":"Learn/Sensitive-Information-Redaction.html#testing-logs-redaction-patterns","title":"Testing logs redaction patterns","text":"<p>You can easily test the patterns you want to configure before deploying by using our docker image and our utilities command.</p> <pre><code>\u276f docker run --rm -e KOMOKW_REDACT_LOGS=\"redaction\" komodorio/k8s-watcher test -logredactor -inputlog=\"The log line you want to test redaction here\"\n\nPatterns to redact: [redaction]\n\nInput log (before redaction):\nThe log line you want to test redaction here\n\nOutput log (after redaction):\nThe log line you want to test &lt;REDACTED&gt; here\n</code></pre>"},{"location":"Learn/SlackApp.html","title":"SlackApp","text":""},{"location":"Learn/SlackApp.html#komodors-workflow-finder","title":"Komodor's Workflow Finder","text":"<p>Workflow finder is a slack application intended to generate links from Slack directly to your workflow inside of Komodor. All you need to do is provide a cluster name, and workflow name, and the link will be generated for you directly into Komodor.</p> <p>To install the application follow this link: https://slack.com/oauth/v2/authorize?client_id=1183152337187.4748628445424&amp;scope=commands&amp;user_scope=</p>"},{"location":"Learn/Static-Prevention.html","title":"Static Prevention","text":""},{"location":"Learn/Static-Prevention.html#introduction","title":"Introduction","text":"<p>Komodor not only provides you with remediation instructions when troubleshooting Kubernetes incidents, but also helps to prevent them from happening in the first place.</p>"},{"location":"Learn/Static-Prevention.html#how-it-works","title":"How it works?","text":"<p>Each time a workload is rolled out, and a change has been made to the workload YAML, Komodor runs a set of statical  checks in order to improve your YAML\u2019s reliability and efficiency.  The results of our scan are presented under the \"Best Practices\u201d section within every service.</p> <p>If you wish to ignore any check, just click on the <code>ignore</code> button under the <code>Best practices</code> pop-up.</p>"},{"location":"Learn/Static-Prevention.html#checks-we-run","title":"Checks we run","text":""},{"location":"Learn/Static-Prevention.html#-deployment-missing-replicas","title":"- Deployment Missing Replicas","text":"<pre><code>What is checked?\n    Check if there is only one replica for a deployment.\nWhy should this be checked?\n    More than one replica recommended to be scheduled.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-tag-not-specified","title":"- Tag Not Specified","text":"<pre><code>What is checked?\nCheck if an image tag is either not specified or the latest tag has not been used.\nWhy should this be checked?\nDocker's latest tag is applied by default to images where a tag hasn't been specified. Not specifying a specific version of an image can lead to a wide variety of problems.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-pull-policy-not-always","title":"- Pull Policy Not Always","text":"<pre><code>What is checked?\nCheck if an image pull policy is not always.\nWhy should this be checked?\nBy default, an image will be pulled if it isn't already cached on the node attempting\nto run it. This can result in variations in images that are running per node, or potentially provide a way to gain access to an image without having direct access to the ImagePullSecret.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-liveness-probe-missing","title":"- Liveness Probe Missing","text":"<pre><code>What is checked?\n    Check if a liveness probe is not configured for a pod.\nWhy should this be checked?\n    Liveness probes are designed to ensure that an application stays in a healthy state.\n    When a liveness probe fails, the pod will be restarted.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-readiness-probe-missing","title":"- Readiness Probe Missing","text":"<pre><code>What is checked?\n    Check if a readiness probe is not configured for a pod.\nWhy should this be checked?\n    A readiness probe can ensure that the traffic is not sent to a pod until it is actually ready to receive the traffic.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-cpu-requests-missing","title":"- CPU Requests Missing","text":"<pre><code>What is checked?\n    Check if resources.requests.cpu attribute is not configured.\nWhy should this be checked?\n    Setting appropriate resource requests will ensure that all your applications have\nsufficient compute CPU resources.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-cpu-limits-missing","title":"- CPU Limits Missing","text":"<pre><code>What is checked?\n    Check if resources.limits.cpu attribute is not configured.\nWhy should this be checked?\n    Setting appropriate resource limits will ensure that your applications do not consume too many CPU resources.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-memory-requests-missing","title":"- Memory Requests Missing","text":"<pre><code>What is checked?\n    Check if resources.requests.memory attribute is not configured.\nWhy should this be checked?\n    Setting appropriate resource requests will ensure that all your applications have\nsufficient memory compute resources.\n</code></pre>"},{"location":"Learn/Static-Prevention.html#-memory-limits-missing","title":"- Memory Limits Missing","text":"<pre><code>What is checked?\n    Check if resources.limits.memory attribute is not configured.\nWhy should this be checked?\n    Setting appropriate resource limits will ensure that your applications do not consume\ntoo many memory resources.\n</code></pre>"},{"location":"Learn/Test-Utilities-Commands.html","title":"Test Utilities Commands","text":""},{"location":"Learn/Test-Utilities-Commands.html#komodor-agent-test-utilities","title":"Komodor Agent Test Utilities","text":"<p>You can use the <code>komodorio/k8s-watcher</code> docker image to run the <code>test</code> command.</p> <pre><code>Komodor Agent Test Utilities\nUsage:\n-clusterconnectivity\nRun utility to test connectivity to Kubernetes API.\n-connectivity\nRun utility to test connectivity to Komodor's API. Requires env var: [KOMOKW_API_KEY]\n-inputlog string\nUsed in conjunction with -logredactor to provide an input log to redact (default \"Example log with supersecret password:abc123 and username=root\")\n-logredactor\nRun utility to test data redaction for pod logs. Requires env var: [KOMOKW_REDACT_LOG]\n</code></pre>"},{"location":"Learn/Test-Utilities-Commands.html#testing-connectivity-to-komodor-api","title":"Testing connectivity to Komodor API","text":"<pre><code>\u276f docker run --rm -e KOMOKW_API_KEY=\"YOUR_API_KEY\" komodorio/k8s-watcher test -connectivity\nno configuration file found, starting with env vars / defaults\ntime=\"2022-09-15T13:27:29Z\" level=info msg=\"Using cluster name &lt;production&gt; from context\"\ntime=\"2022-09-15T13:27:29Z\" level=info msg=\"Identifying agent with Komodor servers\" agentId=xxx serverHost=\"https://app.komodor.com\"\ntime=\"2022-09-15T13:27:30Z\" level=info msg=\"Successfully connected to Komodor API !!!\"\n</code></pre>"},{"location":"Learn/Test-Utilities-Commands.html#testing-connectivity-to-kubernetes-api","title":"Testing connectivity to Kubernetes API","text":"<pre><code>\u276f docker run --rm -v $HOME/.kube/config:/root/.kube/config komodorio/k8s-watcher test -clusterconnectivity\nno configuration file found, starting with env vars / defaults\nRunning outside kubernetes - using kubeconfig file: /Users/mickael/.kube/config\nSuccessfully connected to Kubernetes API !!!  kubernetesServerInfo=v1.22.12-gke.2300\nAvailable API Groups:\ncore\n    v1\napiregistration.k8s.io\n    apiregistration.k8s.io/v1\napps\n    apps/v1\n...\n...\n</code></pre>"},{"location":"Learn/Test-Utilities-Commands.html#testing-logs-redaction-patterns","title":"Testing logs redaction patterns","text":"<p>You can easily test the patterns you want to configure before deploying by using our docker image and our utilities command.</p> <pre><code>\u276f docker run --rm -e KOMOKW_REDACT_LOGS=\"redaction\" komodorio/k8s-watcher test -logredactor -inputlog=\"The log line you want to test redaction here\"\n\nPatterns to redact: [redaction]\n\nInput log (before redaction):\nThe log line you want to test redaction here\n\nOutput log (after redaction):\nThe log line you want to test &lt;REDACTED&gt; here\n</code></pre>"},{"location":"Learn/config-changes.html","title":"Config Change API Integration","text":"<p>Config change API allows users to send changes in their config (from internal tools and infrastructure), and see them as part of the Komodor Service view.</p>"},{"location":"Learn/config-changes.html#how-to-use","title":"How to use","text":""},{"location":"Learn/config-changes.html#request-url","title":"Request URL","text":"<p>Mandatory query params will be used for service selection:</p> <ul> <li>serviceName</li> <li>namespace</li> <li>clusterName</li> </ul> <p>URL example https://api.komodor.com/v0/config_change?serviceName=backend-service&amp;namespace=default&amp;clusterName=production\"</p>"},{"location":"Learn/config-changes.html#authentication","title":"Authentication","text":"<p>To authenticate the request use API Key on your \"REST API\" integration tile in the Komodor app and add it to a header with <code>X-API-KEY</code> name.</p> <p>The REST API key can be found in the Integration page.</p> <p>If REST API integration isn't available for your account, please contact your account manager in Komodor.</p>"},{"location":"Learn/config-changes.html#body","title":"Body","text":"<p>This is the event itself with the relevant configuration you want to be connected to the service as JSON. <code>{ key1: value1, key2: value2\u2026 }</code></p>"},{"location":"Learn/config-changes.html#config-map-and-secrets","title":"Config map and Secrets","text":"<p>Configmap and Secrets can be shown in events tab, please contact us if you want this option. Configmaps that include the coming words will be ignored:</p> <ul> <li>\"istio\"</li> <li>\"cluster-autoscaler-status\"</li> </ul>"},{"location":"Learn/config-changes.html#full-example","title":"Full Example","text":"<p><code>curl -H \"X-API-KEY: &lt;rest api key&gt;\" -H \"Content-Type: application/json\" -d '{\"key\":\"value\"}' \"https://api.komodor.com/v0/config_change?serviceName=backend-service&amp;namespace=default&amp;clusterName=production\"</code></p>"},{"location":"Learn/komodor-source-control.html","title":"Komodor source control support","text":""},{"location":"Learn/komodor-source-control.html#what-is-it","title":"What is it","text":"<p>Enrich services with relevant source control metadata. This allows to show smart-diffs as part of Komodor service changes tracking. Doing so connects the specific service with repositories that might not be the original codebase, such as infrastructure or CI repos, which are still relevant changes.</p>"},{"location":"Learn/komodor-source-control.html#how-to-integrate","title":"How to integrate","text":"<p>Add the following annotations to your service's Kubernetes spec:</p> <pre><code>    app.komodor.com/[name]: FULL_REPO_URL\napp.komodor.com/[name].ref: SOURCE_CONTROL_REF\napp.komodor.com/[another-name]: ANOTHER_FULL_REPO_URL\napp.komodor.com/[another-name].ref: ANOTHER_ SOURCE_CONTROL_REF    </code></pre>"},{"location":"Learn/komodor-source-control.html#full-example","title":"Full example","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: git-example\nannotations:\napp.komodor.com/app: https://github.com/komodorio/infra\napp.komodor.com/app.ref: 3350e3311f9520fe5e237e2d71f339029ee051d8     app.komodor.com/infra: https://github.com/komodorio/helm-charts\napp.komodor.com/infra.ref: 32b355df32713afc511528d909eff296e91dbe74 spec:\nselector:\nmatchLabels:\nrun: example\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\nrun: example\nspec:\ncontainers:\n- name: hello-world\nimage: gcr.io/google-samples/node-hello:1.0\nports:\n- containerPort: 8080\nprotocol: TCP\n</code></pre>"},{"location":"Learn/komodor-source-control.html#microsoft-devops-pipelines-example","title":"Microsoft DevOps Pipelines Example","text":"<p>Microsoft DevOps Pipelines provides predefined variables that contains all the data needed to configure the source control annotations. Modify your pipeline to use these variables when templating the Kubernetes manifests. </p> <pre><code>annotations:\napp.komodor.com/app: $(Build.Repository.Uri)\napp.komodor.com/app.ref: $(Build.SourceVersion)\n</code></pre>"},{"location":"Learn/komodor-source-control.html#tracked-files","title":"Tracked Files","text":"<p>Once the integration with Github is established, Komodor will scan the pull requests files (only the names), to see if there are common, interesting files that have been updated. For example, when there was a change in <code>Dockerfile</code>, Komodor will show that in the Deploy summary.</p> <p>To customize which files will be tracked by Komodor. Using Kubernetes annotation <code>app.komodor.com/tracked_files</code> that accepts multiline string (gitignore like) to specify the files.  For example, track any <code>yaml</code> files:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: git-example\nannotations:\napp.komodor.com/tracked_files: |\n*.yaml\napp.komodor.com/app: https://github.com/komodorio/infra\napp.komodor.com/app.ref: 3350e3311f9520fe5e237e2d71f339029ee051d8     app.komodor.com/infra: https://github.com/komodorio/helm-charts\napp.komodor.com/infra.ref: 32b355df32713afc511528d909eff296e91dbe74 spec:\nselector:\nmatchLabels:\nrun: example\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\nrun: example\nspec:\ncontainers:\n- name: hello-world\nimage: gcr.io/google-samples/node-hello:1.0\nports:\n- containerPort: 8080\nprotocol: TCP\"\n</code></pre>"},{"location":"Learn/Actions/Overview.html","title":"Actions (initial release)","text":"<p>To allow our users to close the troubleshooting loop through Komodor, we\u2019re adding the ability to perform Actions through the platform.</p> <p>Using Komodor you can run multiple actions against your resource. You'll be able to easily track what was done and by whom.</p>"},{"location":"Learn/Actions/Overview.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Agent version 0.1.104</li> <li>Required permissions (permissions can be modified as needed)</li> </ul> <pre><code>  - apiGroups:\n    - apps\n    resources:\n    - deployments/scale\n    - statefulsets/scale\n    - deployments\n    - replicasets\n    - statefulsets\n    - daemonsets\n    verbs:\n    - patch\n  - apiGroups:\n    - \"\"\n    resources:\n    - pods\n    verbs:\n    - delete\n  - apiGroups:\n    - batch\n    resources:\n    - jobs\n    verbs:\n    - delete\n    - create\n  - apiGroups:\n    - \"\"\n    resources:\n    - pods\n    - persistentvolumeclaims\n    - configmaps\n    - services\n    - persistentvolumes\n    - storageclasses\n    verbs:\n    - delete\n    - patch\n    - update\n    - create\n  - apiGroups:\n    - apps\n    resources:\n    - replicasets\n    - deployments\n    - statefulsets\n    - daemonsets\n    verbs:\n    - delete\n    - patch\n    - update\n    - create\n  - apiGroups:\n    - batch\n    resources:\n    - cronjobs\n    - jobs\n    verbs:\n    - delete\n    - patch\n    - update\n    - create\n  - apiGroups:\n    - networking.k8s.io\n    resources:\n    - ingresses\n    - networkpolicies\n    verbs:\n    - delete\n    - patch\n    - update\n    - create\n  - apiGroups:\n    - \"\"\n    resources:\n    - nodes\n    verbs:\n    - patch\n  - apiGroups:\n    - \"\"\n    resources:\n    - pods/eviction\n    verbs:\n    - create\n</code></pre> <ul> <li>Please note: To perform actions against your resources, the user have to be either an <code>account-admin</code> or be provided with permission to perform actions, to read more about Komodor RBAC</li> </ul>"},{"location":"Learn/Actions/Overview.html#how-to-opt-in","title":"How to opt-in","text":"<p>For convienece purposes we've seperated the actions helm chart values into two sections - watcher.actions.basic - Enables basic actions (Delete pods, Scale and restart deployments, statefulsets, replicasets. Restart and trigger jobs) - watcher.actions.advanced - Enables advanced actions (Update, Create and Delete resources, Cordon/Uncordon nodes)  </p>"},{"location":"Learn/Actions/Overview.html#new-cluster-installation","title":"New cluster installation","text":"<p>To install a new cluster with actions enabled just follow the installation process from the Komodor console</p> <p></p>"},{"location":"Learn/Actions/Overview.html#cluster-upgrade","title":"Cluster upgrade","text":"<pre><code>helm repo add komodorio https://helm-charts.komodor.io ; helm repo update; helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.actions.basic=true --set watcher.actions.advanced=true --reuse-values\n</code></pre>"},{"location":"Learn/Actions/Overview.html#how-to-revoke","title":"How to revoke","text":"<p>To disable the usage of Actions using helm, use the following command:</p> <pre><code>helm repo add komodorio https://helm-charts.komodor.io ; helm repo update; helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.actions.basic=false --set watcher.actions.advanced=false --reuse-values\n</code></pre>"},{"location":"Learn/Actions/Overview.html#how-does-it-work","title":"How does it work?","text":"<ul> <li>User triggers a Manual Action through the Komodor platform </li> <li>A command is registered to the Komodor SaaS </li> <li>The Agent running in the cluster fetches the command from the Komodor SaaS (communication is always done from the Agent outside of the cluster) </li> <li>The command is triggered against the Kuberenetes API </li> <li>Kubernetes will now execute the command</li> <li>During the entire process you can track the changes/events through a dedicated Event that will be created on the Komodor timeline.</li> </ul> <p>Please note: Due to Kubernetes nature, this feature is built in an asynchronous way, review the timeline after triggering any action for updates</p> <p> </p>"},{"location":"Learn/Actions/Overview.html#audit","title":"Audit","text":"<p>For auditing purposes, Manual Actions events are created on the Komodor timeline</p>"},{"location":"Learn/Actions/Overview.html#what-type-of-actions-are-supported-and-where-can-they-be-triggered-from","title":"What type of Actions are supported and where can they be triggered from?","text":"<p>We currently support the following actions: - Scale service - Allows modifying the number of replicas for a Service. Can be triggered from Deployment/StatefulSet inspection pages (under Workloads) and also from a Service timeline page - Delete Pod - Deletes/kills a specific Pod. Can be triggered from both the Pod inspection page (under Workloads) and the Pods &amp; Logs screen - Restart service - Triggers a rolling restart of all the Pods of a Service. Can be triggered from Deployment/StatefulSet inspection page (under Workloads) ans also from a Service timeline page - Rollback service - Rolls back a service to the previous generation - Re-trigger Job/CronJob - Re-creates the Job to trigger a new run of it. Can be triggered from a Job/CronJob timeline, Job/CronJob inspection pages (under Workloads) and from a Job event drawer - Cordon/Uncordon node - Allows marking a node as unscehduable, preventing new Pods from being scheduled on it. You can revert this by using the Uncordon action - Delete/Edit resources  </p>"},{"location":"Learn/Actions/PodExec.html","title":"Pod Shell","text":"<p>Pod shell allows you to initiate a shell session against containers in your clusters so you can run various commands to examine the state of the container from within.</p> <p>In essense, it is similar to the experience provided by the <code>kubectl exec -it POD_NAME -- /bin/bash</code> command</p>"},{"location":"Learn/Actions/PodExec.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Agent version &gt;= 0.1.173</li> <li>Prerequisites for performing actions via the agent (see here)</li> <li>Required Permissions</li> </ul> <pre><code>  - apiGroups:\n      - \"\"\nresources:\n      - pods/exec\nverbs:\n      - create\n</code></pre>"},{"location":"Learn/Actions/PodExec.html#opting-in","title":"Opting-in","text":"<p>For convienece, the following flag has been added to configure the agent to support pod shell access:</p> <p><code>watcher.actions.podExec=true</code></p>"},{"location":"Learn/Actions/PodExec.html#agent-upgrade","title":"Agent Upgrade","text":"<p>To upgrade an existing agent to supports pod shell access execute the following command:</p> <p><code>helm repo add komodorio https://helm-charts.komodor.io ; helm repo update; helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.actions.basic=true --set watcher.actions.advanced=true --set watcher.actions.podExec=true --reuse-values</code></p>"},{"location":"Learn/Actions/PodExec.html#revoking-shell-access","title":"Revoking Shell Access","text":"<p>If you would like to revoke only pod shell access run the following command:</p> <p><code>helm repo add komodorio https://helm-charts.komodor.io ; helm repo update; helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.actions.podExec=false --reuse-values</code></p> <p>If you would also like to revoke actions permission from the agent run the following command:</p> <p><code>helm repo add komodorio https://helm-charts.komodor.io ; helm repo update; helm upgrade --install k8s-watcher komodorio/k8s-watcher --set watcher.actions.basic=false --set watcher.actions.advanced=false --set watcher.actions.podExec=false --reuse-values</code></p>"},{"location":"Learn/Actions/PodExec.html#accessing-pod-shell","title":"Accessing pod shell","text":"<p>Pod shell is accessible from two main places in Komodor</p>"},{"location":"Learn/Actions/PodExec.html#option-1-via-pods-page","title":"Option 1: Via Pods Page","text":"<p>Navigate to pods page on the left navbar </p> <p>Select a pod in Running state </p> <p>Either Click on actions -&gt; PodExec </p> <p>OR Click the pod row -&gt; Click Pod Shell button on the top</p> <p></p> <p>The shell is opened</p> <p></p>"},{"location":"Learn/Actions/PodExec.html#option-2-via-service-page","title":"Option 2: Via Service Page","text":"<p>Select the services page on the left navbar </p> <p>Select a service with at least one healthy pod </p> <p>Select the pods tab </p> <p>Select a pod in Running state</p> <p></p> <p>Either click on actions -&gt; Pod Exec</p> <p></p> <p>Or click on the pod row -&gt; Click on Pod Shell button on the top</p> <p></p> <p>The shell is opened </p>"},{"location":"Learn/Actions/PodExec.html#how-does-it-work","title":"How does it work?","text":"<ul> <li>Both client and agent keep a persistent connection to Komodor's backend</li> <li>Client initiates a pod shell session</li> <li>If there are multiple containers the user will have to choose the container to open the shell session to</li> <li>Authentication and authoriztion take place to make sure the client has permissions to run a shell session against the requested pod</li> <li>An audit record and an event on the corresponding service timeline are created so you can track pod shell usage</li> <li>The agent receives the message and opens a shell session against the requested pod and container using the Kubernetes API</li> <li>All subsequent messages are passed from the Client to the Agent, injected into the session and then routed back to the Client for display</li> <li>The agent will close the shell session if the client closes the session voluntarily or if the session has been idle for more than 5 minutes.</li> </ul> <p>Please note: Agent restarts will cause the session to restart and any in-session state will be lost (environment variables for example)</p> <p>The remote container has to have either <code>sh</code> or <code>bash</code> installed on it in order to open a shell session against it</p>"},{"location":"Learn/Actions/PodExec.html#multiple-shells-shell-minimization","title":"Multiple Shells &amp; Shell Minimization","text":"<p>You can minimize a shell session. The session will be kept in a tab in the bottom side of the web application. While it is minimized, you can keep exploring your system, move between different pages and interact regularly with the web application. When you'd like to resume to the shell session, click the tab on the bottom of the screen and the terminal will be displayed again.</p> <p>You can also open and keep multiple shell sessions minimized. In this case you will be able to choose which session you'd like to resume to by using the select menu from the shells tab on the bottom side of the web application.</p> <p></p>"}]}